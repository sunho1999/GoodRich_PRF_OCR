#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from flask import Flask, render_template, request, jsonify, session, send_file
from flask_socketio import SocketIO, emit
import os
import json
import tempfile
import threading
from datetime import datetime
import logging
from werkzeug.utils import secure_filename

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from parsing.pdf_text import PDFTextExtractor
from llm.gpt_summarizer import GPTSummarizer
from core.config import settings

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
app.config['SECRET_KEY'] = 'pdf_ocr_analysis_secret_key_2024'
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB ì œí•œ

# SocketIO ì´ˆê¸°í™” (ì‹¤ì‹œê°„ ì±„íŒ…ìš©)
socketio = SocketIO(app, cors_allowed_origins="*")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì—…ë¡œë“œ í´ë” ì„¤ì •
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'pdf'}

if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

class WebAnalyzer:
    """ì›¹ ê¸°ë°˜ PDF ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.config = settings
        self.pdf_extractor = PDFTextExtractor()
        
        # ì‚¬ìš©ìë³„ ë¶„ì„ ë°ì´í„° ì €ì¥ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
        self.user_data = {}
        
        # GPT ì´ˆê¸°í™” (ë” ê°•ë ¥í•œ ì—ëŸ¬ ì²˜ë¦¬)
        try:
            # .env íŒŒì¼ì—ì„œ API í‚¤ ìš°ì„  ë¡œë“œ
            from dotenv import load_dotenv
            load_dotenv()  # .env íŒŒì¼ ê°•ì œ ë¡œë“œ
            
            # .env íŒŒì¼ -> config -> ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ ìˆœì„œë¡œ ìš°ì„ ìˆœìœ„
            api_key = self.config.openai_api_key or os.getenv('OPENAI_API_KEY')
            logger.info(f"API í‚¤ í™•ì¸: {'ìˆìŒ' if api_key else 'ì—†ìŒ'}")
            
            if not api_key:
                raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            
            self.gpt_summarizer = GPTSummarizer(api_key=api_key)
            self.gpt_available = True
            logger.info("âœ… GPT API ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            self.gpt_summarizer = None
            self.gpt_available = False
            logger.error(f"âŒ GPT API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ ê¸°ë³¸ í…ìŠ¤íŠ¸ íŒŒì‹± ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤")
    
    def allowed_file(self, filename):
        """í—ˆìš©ëœ íŒŒì¼ í™•ì¥ì í™•ì¸"""
        return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS
    
    def get_user_id(self, request):
        """ì‚¬ìš©ì ID ìƒì„± (IP + User-Agent ê¸°ë°˜)"""
        import hashlib
        user_info = f"{request.remote_addr}_{request.headers.get('User-Agent', '')}"
        return hashlib.md5(user_info.encode()).hexdigest()[:16]
    
    def get_user_data(self, user_id):
        """ì‚¬ìš©ì ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        if user_id not in self.user_data:
            self.user_data[user_id] = {
                'analyzed_products': [],
                'last_activity': datetime.now()
            }
        return self.user_data[user_id]
    
    def save_analysis_result(self, user_id, product_info):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        user_data = self.get_user_data(user_id)
        user_data['analyzed_products'].append(product_info)
        user_data['last_activity'] = datetime.now()
        
        # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ì €ì¥
        if len(user_data['analyzed_products']) > 5:
            user_data['analyzed_products'] = user_data['analyzed_products'][-5:]
        
        logger.info(f"ì‚¬ìš©ì {user_id}ì˜ ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨: {product_info['name']}")
    
    def get_analyzed_products(self, user_id):
        """ë¶„ì„ëœ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        user_data = self.get_user_data(user_id)
        return user_data['analyzed_products']
    
    def cleanup_old_data(self):
        """ì˜¤ë˜ëœ ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬ (1ì‹œê°„ ì´ìƒ)"""
        from datetime import timedelta
        cutoff_time = datetime.now() - timedelta(hours=1)
        
        old_users = [
            user_id for user_id, data in self.user_data.items()
            if data['last_activity'] < cutoff_time
        ]
        
        for user_id in old_users:
            del self.user_data[user_id]
            
        if old_users:
            logger.info(f"ì˜¤ë˜ëœ ì‚¬ìš©ì ë°ì´í„° ì •ë¦¬: {len(old_users)}ëª…")
    
    def extract_pdf_content(self, file_path_or_url, is_url=False, use_ocr=True):
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR í–¥ìƒ í¬í•¨)"""
        try:
            if is_url:
                success, pages = self.pdf_extractor.extract_text_from_url(file_path_or_url)
            else:
                success, pages = self.pdf_extractor.extract_text_from_pdf(file_path_or_url, use_ocr=use_ocr)
            
            if not success:
                return {
                    'success': False, 
                    'error': 'PDF í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
                }
            
            # ê¸°ë³¸ í…ìŠ¤íŠ¸ ê²°í•© ë° ì¶”ì¶œ í†µê³„ ìƒì„±
            combined_text = ""
            extraction_stats = {
                'total_pages': len(pages),
                'pages_with_text': 0,
                'ocr_enhanced_pages': 0,
                'hybrid_pages': 0,
                'extraction_methods': {}
            }
            
            for page in pages:
                if isinstance(page, dict):
                    text = page.get('text', '')
                    page_num = page.get('page_number', 0)
                    extraction_method = page.get('extraction_method', 'unknown')
                    
                    # í…ìŠ¤íŠ¸ ê²°í•©
                    if text.strip():
                        extraction_stats['pages_with_text'] += 1
                        combined_text += f"\n--- í˜ì´ì§€ {page_num} ---\n{text}\n"
                    
                    # ì¶”ì¶œ ë°©ë²• í†µê³„
                    if extraction_method in extraction_stats['extraction_methods']:
                        extraction_stats['extraction_methods'][extraction_method] += 1
                    else:
                        extraction_stats['extraction_methods'][extraction_method] = 1
                    
                    # OCR í†µê³„
                    if page.get('has_ocr', False):
                        extraction_stats['ocr_enhanced_pages'] += 1
                    if extraction_method == 'hybrid':
                        extraction_stats['hybrid_pages'] += 1
            
            return {
                'success': True,
                'pages': pages,
                'content': combined_text,
                'page_count': len(pages),
                'extraction_stats': extraction_stats
            }
            
        except Exception as e:
            logger.error(f"PDF ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'error': f'PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }
    
    def analyze_product_detail(self, pages, file_name):
        """ìƒí’ˆ ìƒì„¸ ë¶„ì„"""
        if not self.gpt_available:
            return "âŒ GPT APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í…ìŠ¤íŠ¸ë§Œ ì œê³µë©ë‹ˆë‹¤."
        
        try:
            return self.gpt_summarizer.analyze_for_detail(pages, file_name)
        except Exception as e:
            logger.error(f"GPT ìƒì„¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def analyze_product_comparison(self, pages, file_name):
        """ìƒí’ˆ ë¹„êµ ë¶„ì„"""
        if not self.gpt_available:
            return "âŒ GPT APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í…ìŠ¤íŠ¸ë§Œ ì œê³µë©ë‹ˆë‹¤."
        
        try:
            return self.gpt_summarizer.analyze_for_comparison(pages, file_name)
        except Exception as e:
            logger.error(f"GPT ë¹„êµ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def generate_chatbot_response(self, question, context):
        """ì±—ë´‡ ì‘ë‹µ ìƒì„±"""
        if not self.gpt_available:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. GPT APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ AI ìƒë‹´ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤."
        
        try:
            prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ë³´í—˜ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ë¶„ì„ëœ ìƒí’ˆ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
            
            messages = [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ ë³´í—˜ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
            
            response = self.gpt_summarizer._safe_api_call(
                messages=messages, 
                max_tokens=1000, 
                retries=2, 
                delay=1
            )
            
            if response is None:
                return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì‘ë‹µ ìƒì„±ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"ì±—ë´‡ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
analyzer = WebAnalyzer()

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index.html', gpt_available=analyzer.gpt_available)

@app.route('/api/upload', methods=['POST'])
def upload_file():
    """íŒŒì¼ ì—…ë¡œë“œ API"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'})
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'})
        
        if not analyzer.allowed_file(file.filename):
            return jsonify({'success': False, 'error': 'PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.'})
        
        # ì•ˆì „í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_{filename}"
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        
        file.save(file_path)
        
        return jsonify({
            'success': True, 
            'file_path': file_path,
            'filename': filename
        })
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': f'ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})

@app.route('/api/analyze/individual', methods=['POST'])
def analyze_individual():
    """ê°œë³„ ìƒí’ˆ ë¶„ì„ API"""
    try:
        data = request.get_json()
        source_type = data.get('source_type')  # 'file' or 'url'
        source = data.get('source')
        product_name = data.get('product_name', 'ìƒí’ˆ')
        
        if not source:
            return jsonify({'success': False, 'error': 'ë¶„ì„í•  ì†ŒìŠ¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'})
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        is_url = (source_type == 'url')
        result = analyzer.extract_pdf_content(source, is_url=is_url)
        
        if not result['success']:
            return jsonify(result)
        
        # GPT ìƒì„¸ ë¶„ì„ (ê°€ëŠ¥í•œ ê²½ìš°)
        analysis = ""
        gpt_analysis_success = False
        
        if analyzer.gpt_available:
            analysis = analyzer.analyze_product_detail(result['pages'], product_name)
            # GPT ë¶„ì„ì´ ì‹¤ì œë¡œ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸
            gpt_analysis_success = (
                analysis and 
                not analysis.startswith("âŒ") and 
                not "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ" in analysis and
                not "API í˜¸ì¶œì— ì‹¤íŒ¨" in analysis
            )
            logger.info(f"GPT ë¶„ì„ ì„±ê³µ: {gpt_analysis_success}")
        
        # ë©”ëª¨ë¦¬ì— ë¶„ì„ ê²°ê³¼ ì €ì¥ (ì±—ë´‡ìš©)
        user_id = analyzer.get_user_id(request)
        analyzer.save_analysis_result(user_id, {
            'name': product_name,
            'content': result['content'],
            'analysis': analysis,
            'timestamp': datetime.now().isoformat()
        })
        
        return jsonify({
            'success': True,
            'content': result['content'],
            'analysis': analysis,
            'page_count': result['page_count'],
            'gpt_used': gpt_analysis_success,  # ì‹¤ì œ ì„±ê³µ ì—¬ë¶€ë¡œ ë³€ê²½
            'extraction_stats': result.get('extraction_stats', {})
        })
        
    except Exception as e:
        logger.error(f"ê°œë³„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})

@app.route('/api/get_raw_text', methods=['POST'])
def get_raw_text():
    """ì›ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ API (ë””ë²„ê¹…ìš©)"""
    try:
        data = request.get_json()
        source = data.get('source')
        source_type = data.get('source_type', 'file')
        
        if not source:
            return jsonify({'success': False, 'error': 'ì†ŒìŠ¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'})
        
        is_url = (source_type == 'url')
        result = analyzer.extract_pdf_content(source, is_url=is_url)
        
        if not result['success']:
            return jsonify(result)
        
        return jsonify({
            'success': True,
            'raw_text': result['content'],
            'page_count': result['page_count'],
            'extraction_stats': result.get('extraction_stats', {})
        })
        
    except Exception as e:
        logger.error(f"ì›ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': f'ì›ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})

@app.route('/api/analyze/compare', methods=['POST'])
def analyze_compare():
    """2ê°œ ìƒí’ˆ ë¹„êµ ë¶„ì„ API"""
    try:
        data = request.get_json()
        
        # ì²« ë²ˆì§¸ ìƒí’ˆ
        source1_type = data.get('source1_type')
        source1 = data.get('source1')
        product1_name = data.get('product1_name', 'ìƒí’ˆ A')
        
        # ë‘ ë²ˆì§¸ ìƒí’ˆ
        source2_type = data.get('source2_type')
        source2 = data.get('source2')
        product2_name = data.get('product2_name', 'ìƒí’ˆ B')
        
        if not source1 or not source2:
            return jsonify({'success': False, 'error': 'ë¹„êµí•  ë‘ ê°œì˜ ì†ŒìŠ¤ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.'})
        
        # ì²« ë²ˆì§¸ ìƒí’ˆ ë¶„ì„
        result1 = analyzer.extract_pdf_content(source1, is_url=(source1_type == 'url'))
        if not result1['success']:
            return jsonify({'success': False, 'error': f'ì²« ë²ˆì§¸ ìƒí’ˆ ë¶„ì„ ì‹¤íŒ¨: {result1["error"]}'})
        
        # ë‘ ë²ˆì§¸ ìƒí’ˆ ë¶„ì„
        result2 = analyzer.extract_pdf_content(source2, is_url=(source2_type == 'url'))
        if not result2['success']:
            return jsonify({'success': False, 'error': f'ë‘ ë²ˆì§¸ ìƒí’ˆ ë¶„ì„ ì‹¤íŒ¨: {result2["error"]}'})
        
        # ë¹„êµ ë¶„ì„ ìˆ˜í–‰ (Rate Limit ë°©ì§€)
        comparison_analysis = ""
        analysis1 = ""
        analysis2 = ""
        gpt_comparison_success = False
        
        if analyzer.gpt_available:
            logger.info("ğŸ¤– GPT ì¢…í•© ë¹„êµ ë¶„ì„ ì‹œì‘...")
            
            try:
                # ìƒˆë¡œìš´ ì¢…í•© ë¹„êµ ë¶„ì„ í•¨ìˆ˜ ì‚¬ìš©
                comparison_analysis = analyzer.gpt_summarizer.analyze_products_comparison(
                    result1['pages'], product1_name,
                    result2['pages'], product2_name
                )
                logger.info(f"ğŸ“Š ì¢…í•© ë¹„êµ ë¶„ì„ ê²°ê³¼ ê¸¸ì´: {len(comparison_analysis) if comparison_analysis else 0}")
            except Exception as e:
                logger.error(f"âŒ ì¢…í•© ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                comparison_analysis = f"âŒ ì¢…í•© ë¹„êµ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            
            # ë¶„ì„ ì„±ê³µ ì—¬ë¶€ í™•ì¸
            gpt_comparison_success = (
                comparison_analysis and 
                not comparison_analysis.startswith("âŒ") and 
                not "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ" in comparison_analysis and
                not "API í˜¸ì¶œì— ì‹¤íŒ¨" in comparison_analysis
            )
            
            logger.info(f"GPT ì¢…í•© ë¹„êµ ë¶„ì„ ì„±ê³µ: {gpt_comparison_success}")
            
            if gpt_comparison_success:
                logger.info("âœ… ì¢…í•© ë¹„êµ ë¶„ì„ ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ GPT ì¢…í•© ë¹„êµ ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
                
            # ê°œë³„ ë¶„ì„ë„ ë©”ëª¨ë¦¬ ì €ì¥ìš©ìœ¼ë¡œ ìˆ˜í–‰ (ì„±ê³µí•œ ê²½ìš°ì—ë§Œ)
            if gpt_comparison_success:
                logger.info("ğŸ”„ ê°œë³„ ë¶„ì„ ì‹œì‘ (ë©”ëª¨ë¦¬ ì €ì¥ìš©)...")
                analysis1 = analyzer.analyze_product_comparison(result1['pages'], product1_name)
                time.sleep(1)  # Rate Limit ë°©ì§€
                analysis2 = analyzer.analyze_product_comparison(result2['pages'], product2_name)
            else:
                analysis1 = ""
                analysis2 = ""
        
        # ë©”ëª¨ë¦¬ì— ë¶„ì„ ê²°ê³¼ ì €ì¥
        user_id = analyzer.get_user_id(request)
        analyzer.save_analysis_result(user_id, {
            'name': product1_name,
            'content': result1['content'],
            'analysis': analysis1 if analyzer.gpt_available else "",
            'timestamp': datetime.now().isoformat()
        })
        analyzer.save_analysis_result(user_id, {
            'name': product2_name,
            'content': result2['content'],
            'analysis': analysis2 if analyzer.gpt_available else "",
            'timestamp': datetime.now().isoformat()
        })
        
        return jsonify({
            'success': True,
            'product1': {
                'name': product1_name,
                'content': result1['content'],
                'page_count': result1['page_count']
            },
            'product2': {
                'name': product2_name,
                'content': result2['content'],
                'page_count': result2['page_count']
            },
            'comparison_analysis': comparison_analysis,
            'gpt_used': gpt_comparison_success  # ì‹¤ì œ ì„±ê³µ ì—¬ë¶€ë¡œ ë³€ê²½
        })
        
    except Exception as e:
        logger.error(f"ë¹„êµ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({'success': False, 'error': f'ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})

# WebSocket ì´ë²¤íŠ¸ (ì±—ë´‡ìš©)
@socketio.on('connect')
def handle_connect():
    """í´ë¼ì´ì–¸íŠ¸ ì—°ê²°"""
    logger.info(f"í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {request.sid}")
    emit('status', {'message': 'AI ìƒë‹´ ì„œë¹„ìŠ¤ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.', 'type': 'info'})

@socketio.on('disconnect')
def handle_disconnect():
    """í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ"""
    logger.info(f"í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ: {request.sid}")

@socketio.on('chat_message')
def handle_chat_message(data):
    """ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬"""
    try:
        question = data.get('message', '').strip()
        if not question:
            emit('chat_response', {'error': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'})
            return
        
        # ë¶„ì„ëœ ìƒí’ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë©”ëª¨ë¦¬ì—ì„œ)
        from flask import request as flask_request
        user_id = analyzer.get_user_id(flask_request)
        analyzed_products = analyzer.get_analyzed_products(user_id)
        
        if not analyzed_products:
            emit('chat_response', {
                'response': 'ì•„ì§ ë¶„ì„ëœ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒí’ˆì„ ë¶„ì„í•´ì£¼ì„¸ìš”.',
                'type': 'warning'
            })
            return
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = "ë¶„ì„ëœ ìƒí’ˆ ì •ë³´:\n\n"
        for i, product in enumerate(analyzed_products[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ ì‚¬ìš©
            content_preview = product['content'][:1500]
            context += f"ìƒí’ˆ {i}: {product['name']}\n{content_preview}\n\n"
        
        # ë¡œë”© ìƒíƒœ ì „ì†¡
        emit('chat_response', {'loading': True, 'message': 'AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...'})
        
        # í˜„ì¬ request sid ì €ì¥
        current_sid = request.sid
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ AI ì‘ë‹µ ìƒì„±
        def generate_response():
            try:
                response = analyzer.generate_chatbot_response(question, context)
                socketio.emit('chat_response', {
                    'response': response,
                    'type': 'success',
                    'loading': False
                }, room=current_sid)
            except Exception as e:
                logger.error(f"ì±—ë´‡ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
                socketio.emit('chat_response', {
                    'error': f'ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}',
                    'loading': False
                }, room=current_sid)
        
        thread = threading.Thread(target=generate_response)
        thread.daemon = True
        thread.start()
        
    except Exception as e:
        logger.error(f"ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        emit('chat_response', {'error': f'ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})

def start_app():
    """ì•± ì‹œì‘ í•¨ìˆ˜ - Vercelê³¼ ë¡œì»¬ í™˜ê²½ ëª¨ë‘ ì§€ì›"""
    logger.info("ğŸš€ PDF OCR ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘...")
    logger.info(f"GPT API ìƒíƒœ: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if analyzer.gpt_available else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")
    
    # ì£¼ê¸°ì  ë°ì´í„° ì •ë¦¬ ìŠ¤ì¼€ì¤„ë§
    import threading
    import time
    
    def cleanup_task():
        while True:
            time.sleep(300)  # 5ë¶„ë§ˆë‹¤ ì‹¤í–‰
            analyzer.cleanup_old_data()
    
    cleanup_thread = threading.Thread(target=cleanup_task, daemon=True)
    cleanup_thread.start()
    
    # í™˜ê²½ì— ë”°ë¼ ì‹¤í–‰ ë°©ì‹ ê²°ì •
    debug_mode = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    
    if debug_mode:
        # ê°œë°œ í™˜ê²½
        socketio.run(app, host='0.0.0.0', port=8080, debug=True)
    else:
        # í”„ë¡œë•ì…˜ í™˜ê²½
        socketio.run(app, host='0.0.0.0', port=8080, debug=False, allow_unsafe_werkzeug=True)

# Vercel í™˜ê²½ì—ì„œëŠ” importë§Œ ë˜ê³  ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
# ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰
if __name__ == '__main__':
    start_app()

# Vercelìš© WSGI ì•± export
application = app
