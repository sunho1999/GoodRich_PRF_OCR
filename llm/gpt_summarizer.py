"""
GPT APIë¥¼ ì‚¬ìš©í•œ PDF í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ìš”ì•½ ëª¨ë“ˆ
"""
import os
import time
from typing import Dict, List, Any, Optional
from openai import OpenAI
import logging

# í† í° ê³„ì‚°ì„ ìœ„í•œ import (ì„ íƒì )
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False
    logging.warning("tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê·¼ì‚¬ì¹˜ í† í° ê³„ì‚°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

try:
    from core.gui_config import gui_settings as settings
except ImportError:
    try:
        from core.config import settings
    except ImportError:
        class MinimalSettings:
            openai_api_key = None
            openai_model = "gpt-4"
        settings = MinimalSettings()

try:
    from core.logging import get_logger
    logger = get_logger(__name__)
except ImportError:
    import logging
    logger = logging.getLogger(__name__)
    logging.basicConfig(level=logging.INFO)


class GPTSummarizer:
    def __init__(self, api_key: Optional[str] = None):
        """
        GPT ìš”ì•½ê¸° ì´ˆê¸°í™”
        
        Args:
            api_key: OpenAI API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ)
        """
        # API í‚¤ ì„¤ì • (.env íŒŒì¼ ìš°ì„ )
        from dotenv import load_dotenv
        load_dotenv()  # .env íŒŒì¼ ê°•ì œ ë¡œë“œ
        
        # .env íŒŒì¼ -> ì„¤ì • -> íŒŒë¼ë¯¸í„° -> ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ ìˆœì„œë¡œ ìš°ì„ ìˆœìœ„
        self.api_key = (api_key or 
                       settings.openai_api_key or 
                       os.getenv('OPENAI_API_KEY'))
        
        if not self.api_key:
            raise ValueError(
                "OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë°©ë²•ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”:\n"
                "1. í™˜ê²½ë³€ìˆ˜: OPENAI_API_KEY=your_key\n"
                "2. íŒŒë¼ë¯¸í„°ë¡œ ì§ì ‘ ì „ë‹¬\n"
                "3. core/config.pyì—ì„œ openai_api_key ì„¤ì •"
            )
        
        # API í‚¤ ë””ë²„ê¹… ì •ë³´
        key_preview = f"{self.api_key[:10]}...{self.api_key[-4:]}" if len(self.api_key) > 14 else "****"
        logger.info(f"OpenAI API í‚¤ ë¡œë“œë¨: {key_preview}")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (proxy ì„¤ì • ëª…ì‹œì  ë¹„í™œì„±í™”)
        try:
            import httpx
            # HTTP í´ë¼ì´ì–¸íŠ¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ìƒì„±í•˜ì—¬ proxy ì„¤ì • ì œì–´
            http_client = httpx.Client(
                timeout=30.0,
                follow_redirects=True,
                # proxy ì„¤ì •ì„ ëª…ì‹œì ìœ¼ë¡œ Noneìœ¼ë¡œ ì„¤ì •
                proxies=None
            )
            self.client = OpenAI(
                api_key=self.api_key,
                http_client=http_client
            )
        except Exception as e:
            logger.warning(f"HTTP í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì • ì‚¬ìš©: {e}")
            # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„
            try:
                self.client = OpenAI(api_key=self.api_key)
            except Exception as e2:
                # í™˜ê²½ ë³€ìˆ˜ì—ì„œ proxy ì„¤ì • ì œê±° í›„ ì¬ì‹œë„
                import os
                old_http_proxy = os.environ.pop('HTTP_PROXY', None)
                old_https_proxy = os.environ.pop('HTTPS_PROXY', None)
                old_http_proxy_lower = os.environ.pop('http_proxy', None)
                old_https_proxy_lower = os.environ.pop('https_proxy', None)
                
                try:
                    self.client = OpenAI(api_key=self.api_key)
                    logger.info("proxy í™˜ê²½ë³€ìˆ˜ ì œê±° í›„ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
                except Exception as e3:
                    logger.error(f"ëª¨ë“  ë°©ë²• ì‹¤íŒ¨: {e3}")
                    raise e3
                finally:
                    # í™˜ê²½ë³€ìˆ˜ ë³µì›
                    if old_http_proxy: os.environ['HTTP_PROXY'] = old_http_proxy
                    if old_https_proxy: os.environ['HTTPS_PROXY'] = old_https_proxy
                    if old_http_proxy_lower: os.environ['http_proxy'] = old_http_proxy_lower
                    if old_https_proxy_lower: os.environ['https_proxy'] = old_https_proxy_lower
        # ê°€ì¥ ì €ë ´í•œ ëª¨ë¸ ì‚¬ìš© (gpt-4o-mini)
        self.model = 'gpt-4o-mini'
        
        # API í‚¤ ìœ íš¨ì„± ê²€ì¦
        try:
            test_response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1
            )
            logger.info(f"âœ… OpenAI API í‚¤ ê²€ì¦ ì„±ê³µ")
        except Exception as e:
            logger.error(f"âŒ OpenAI API í‚¤ ê²€ì¦ ì‹¤íŒ¨: {e}")
            raise ValueError(f"OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")
        
        logger.info(f"GPT Summarizer initialized with model: {self.model}")
    
    def _estimate_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤."""
        if TIKTOKEN_AVAILABLE:
            try:
                encoding = tiktoken.encoding_for_model(self.model)
                return len(encoding.encode(text))
            except Exception as e:
                logger.warning(f"tiktoken ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
        
        # ê·¼ì‚¬ì¹˜ ê³„ì‚° (í•œêµ­ì–´: 2ìë‹¹ 1í† í°, ì˜ì–´: 4ìë‹¹ 1í† í°)
        korean_chars = len([c for c in text if ord(c) >= 0xAC00 and ord(c) <= 0xD7A3])
        other_chars = len(text) - korean_chars
        return int(korean_chars / 2 + other_chars / 4)
    
    def _normalize_currency_units(self, text: str) -> str:
        """
        ê¸ˆì•¡ ë‹¨ìœ„ë¥¼ í†µì¼í•˜ì—¬ ì •í™•í•œ ë¹„êµê°€ ê°€ëŠ¥í•˜ë„ë¡ ì •ê·œí™”í•©ë‹ˆë‹¤.
        
        Args:
            text: ì •ê·œí™”í•  í…ìŠ¤íŠ¸
            
        Returns:
            ê¸ˆì•¡ ë‹¨ìœ„ê°€ í†µì¼ëœ í…ìŠ¤íŠ¸
        """
        import re
        
        # ê¸ˆì•¡ íŒ¨í„´ ë§¤ì¹­ ë° ë‹¨ìœ„ í†µì¼
        # 1. ì²œì› ë‹¨ìœ„ (ì˜ˆ: 1,000ì²œì›, 1000ì²œì›)
        thousand_pattern = r'([0-9,]+)\s*ì²œì›'
        def replace_thousand(match):
            amount = match.group(1).replace(',', '')
            try:
                value = int(amount) * 1000
                return f"{value:,}ì›"
            except:
                return match.group(0)
        text = re.sub(thousand_pattern, replace_thousand, text)
        
        # 2. ë§Œì› ë‹¨ìœ„ (ì˜ˆ: 1,000ë§Œì›, 1000ë§Œì›)
        ten_thousand_pattern = r'([0-9,]+)\s*ë§Œì›'
        def replace_ten_thousand(match):
            amount = match.group(1).replace(',', '')
            try:
                value = int(amount) * 10000
                return f"{value:,}ì›"
            except:
                return match.group(0)
        text = re.sub(ten_thousand_pattern, replace_ten_thousand, text)
        
        # 3. ì–µì› ë‹¨ìœ„ (ì˜ˆ: 1ì–µì›, 1.5ì–µì›)
        hundred_million_pattern = r'([0-9.]+)\s*ì–µì›'
        def replace_hundred_million(match):
            amount = match.group(1)
            try:
                value = float(amount) * 100000000
                return f"{int(value):,}ì›"
            except:
                return match.group(0)
        text = re.sub(hundred_million_pattern, replace_hundred_million, text)
        
        # 4. ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° (ì›ì´ ì—†ëŠ” ê²½ìš°) - ë¬¸ë§¥ì— ë”°ë¼ íŒë‹¨
        # ë³´í—˜ë£Œ ê´€ë ¨ ë¬¸ë§¥ì—ì„œ ìˆ«ìë§Œ ìˆìœ¼ë©´ ì› ë‹¨ìœ„ë¡œ ê°€ì •
        premium_context_pattern = r'(ì›”ë³´í—˜ë£Œ|ë³´í—˜ë£Œ|ë‚©ì…|ë³´ì¥ê¸ˆì•¡|ì§€ê¸‰ê¸ˆì•¡)[:ï¼š]\s*([0-9,]+)(?![ì›ì²œë§Œì–µ])'
        def add_won_unit(match):
            prefix = match.group(1)
            amount = match.group(2)
            return f"{prefix}: {amount}ì›"
        text = re.sub(premium_context_pattern, add_won_unit, text)
        
        return text
    
    def _smart_truncate_text(self, text: str, max_input_tokens: int = 100000) -> str:
        """í† í° ì œí•œì„ ê³ ë ¤í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ì ˆë‹¨í•©ë‹ˆë‹¤. (GPT-4o-mini 128K í™œìš©)"""
        current_tokens = self._estimate_tokens(text)
        
        # GPT-4o-miniëŠ” 128K í† í° ì§€ì›í•˜ë¯€ë¡œ ëŒ€ë¶€ë¶„ì˜ PDFëŠ” ì „ì²´ ì²˜ë¦¬ ê°€ëŠ¥
        if current_tokens <= max_input_tokens:
            logger.info(f"âœ… ì „ì²´ í…ìŠ¤íŠ¸ ë³´ì¡´: {current_tokens} í† í° (ì œí•œ: {max_input_tokens})")
            return text
        
        # í† í° ë¹„ìœ¨ ê³„ì‚°
        ratio = max_input_tokens / current_tokens
        target_length = int(len(text) * ratio * 0.9)  # 10% ì—¬ìœ ë¶„
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì ˆë‹¨ ì‹œë„
        sentences = text.split('.')
        truncated = ""
        for sentence in sentences:
            if self._estimate_tokens(truncated + sentence + ".") > max_input_tokens:
                break
            truncated += sentence + "."
        
        if truncated.strip():
            logger.info(f"í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì ˆë‹¨: {current_tokens} â†’ {self._estimate_tokens(truncated)} í† í°")
            return truncated
        
        # ë¬¸ì¥ ë‹¨ìœ„ ì ˆë‹¨ ì‹¤íŒ¨ ì‹œ ë¬¸ì ë‹¨ìœ„ë¡œ ì ˆë‹¨
        truncated = text[:target_length]
        logger.info(f"í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì ë‹¨ìœ„ë¡œ ì ˆë‹¨: {current_tokens} â†’ {self._estimate_tokens(truncated)} í† í°")
        return truncated

    def _safe_api_call(self, messages, max_tokens=1000, retries=3, delay=2):
        """
        Rate Limitì„ ê³ ë ¤í•œ ì•ˆì „í•œ API í˜¸ì¶œ
        
        Args:
            messages: ì±„íŒ… ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            retries: ì¬ì‹œë„ íšŸìˆ˜
            delay: ì¬ì‹œë„ ê°„ê²© (ì´ˆ)
            
        Returns:
            OpenAI API response object or None if failed
        """
        # í† í° ìˆ˜ ì‚¬ì „ ê²€ì¦
        total_input_tokens = sum(self._estimate_tokens(msg.get('content', '')) for msg in messages)
        total_tokens = total_input_tokens + max_tokens
        
        if total_tokens > 125000:  # GPT-4o-mini ì•ˆì „ ë§ˆì§„ (128k - 3k)
            logger.warning(f"í† í° ìˆ˜ ì´ˆê³¼ ìœ„í—˜: {total_tokens} tokens (ì…ë ¥: {total_input_tokens}, ì¶œë ¥: {max_tokens})")
            # ì¶œë ¥ í† í° ìë™ ì¡°ì •
            max_tokens = min(max_tokens, 125000 - total_input_tokens)
            logger.info(f"ì¶œë ¥ í† í° ìë™ ì¡°ì •: {max_tokens}")
        
        logger.info(f"API í˜¸ì¶œ ì˜ˆìƒ í† í°: ì…ë ¥ {total_input_tokens} + ì¶œë ¥ {max_tokens} = {total_tokens}")
        for attempt in range(retries):
            try:
                # Rate Limit ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—°
                if attempt > 0:
                    wait_time = delay * (2 ** attempt)  # ì§€ìˆ˜ì  ë°±ì˜¤í”„
                    logger.info(f"API ì¬ì‹œë„ ëŒ€ê¸°: {wait_time}ì´ˆ")
                    time.sleep(wait_time)
                elif hasattr(self, '_last_api_call'):
                    # ì—°ì† í˜¸ì¶œ ê°„ ìµœì†Œ ê°„ê²© ë³´ì¥ (Rate Limit ë°©ì§€)
                    elapsed = time.time() - self._last_api_call
                    min_interval = 0.5  # 500ms ìµœì†Œ ê°„ê²©
                    if elapsed < min_interval:
                        sleep_time = min_interval - elapsed
                        logger.info(f"Rate Limit ë°©ì§€ ëŒ€ê¸°: {sleep_time:.2f}ì´ˆ")
                        time.sleep(sleep_time)
                
                # API í˜¸ì¶œ ì‹œê°„ ê¸°ë¡
                self._last_api_call = time.time()
                
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.3,
                    max_tokens=max_tokens
                )
                
                # ì„±ê³µ ë¡œê¹…
                logger.info(f"âœ… API í˜¸ì¶œ ì„±ê³µ (ì‹œë„ {attempt + 1}/{retries})")
                
                # ì„±ê³µ ì‹œ ë‹¤ìŒ ìš”ì²­ì„ ìœ„í•œ ì§§ì€ ì§€ì—°
                time.sleep(1)
                return response
                
            except Exception as e:
                error_str = str(e)
                logger.warning(f"API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{retries} ì‹¤íŒ¨: {error_str}")
                
                # ë‹¤ì–‘í•œ ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
                if "429" in error_str or "rate" in error_str.lower():
                    if attempt < retries - 1:
                        wait_time = delay * (2 ** (attempt + 1))
                        logger.warning(f"ğŸš¨ Rate Limit ê°ì§€, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                        time.sleep(wait_time)
                        continue
                elif "context_length_exceeded" in error_str.lower() or ("token" in error_str.lower() and "exceed" in error_str.lower()):
                    logger.error(f"ğŸš¨ í† í° ìˆ˜ ì´ˆê³¼ ê°ì§€: {error_str}")
                    logger.error(f"ğŸ“Š ì˜ˆìƒ í† í°: ì…ë ¥ {sum(self._estimate_tokens(msg.get('content', '')) for msg in messages)} + ì¶œë ¥ {max_tokens}")
                    # í† í° ìˆ˜ ì´ˆê³¼ ì‹œ ë” ì´ìƒ ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                    break
                elif "invalid_api_key" in error_str.lower() or "401" in error_str:
                    logger.error(f"ğŸš¨ API í‚¤ ì˜¤ë¥˜ ê°ì§€: {error_str}")
                    # API í‚¤ ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ë¬´ì˜ë¯¸
                    break
                
                # ë§ˆì§€ë§‰ ì‹œë„ì—ì„œë„ ì‹¤íŒ¨í•˜ë©´ None ë°˜í™˜ (ì˜ˆì™¸ ë°œìƒ ëŒ€ì‹ )
                if attempt == retries - 1:
                    logger.error(f"âŒ API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨: {error_str}")
                    return None
        
        logger.error("API í˜¸ì¶œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
        return None
    
    def format_extracted_text(self, pages: List[Dict[str, Any]], file_name: str) -> str:
        """
        OCRë¡œ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ GPT APIë¡œ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬
        
        Args:
            pages: PDF í˜ì´ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            file_name: PDF íŒŒì¼ëª…
            
        Returns:
            GPTë¡œ ì •ë¦¬ëœ í…ìŠ¤íŠ¸
        """
        try:
            # 1. ì›ë³¸ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸° (ìš”ì•½í•˜ì§€ ì•ŠìŒ)
            raw_text = self._combine_extracted_text(pages)
            
            if not raw_text.strip():
                return "âŒ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # 2. GPT í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_formatting_prompt(raw_text, file_name, len(pages))
            
            # 3. GPT API í˜¸ì¶œ
            logger.info("GPT API í˜¸ì¶œ ì¤‘...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ PDF ë¬¸ì„œ í…ìŠ¤íŠ¸ë¥¼ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ë§ê³ , ì½ê¸° ì‰½ê²Œ êµ¬ì¡°í™”í•˜ê³  í¬ë§·íŒ…í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=4000
            )
            
            formatted_text = response.choices[0].message.content.strip()
            
            # 4. ê¸°ë³¸ ì •ë³´ ì¶”ê°€
            final_result = self._add_document_metadata(formatted_text, file_name, len(pages))
            
            logger.info("GPT í…ìŠ¤íŠ¸ ì •ë¦¬ ì™„ë£Œ")
            return final_result
            
        except Exception as e:
            logger.error(f"GPT í…ìŠ¤íŠ¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # GPT ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í¬ë§· ë°˜í™˜
            return self._fallback_formatting(pages, file_name)
    
    def summarize_extracted_text(self, pages: List[Dict[str, Any]], file_name: str) -> str:
        """
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ GPTë¡œ ìš”ì•½ (ì›í•˜ëŠ” í”„ë¡œì„¸ìŠ¤)
        
        Args:
            pages: PDF í˜ì´ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            file_name: PDF íŒŒì¼ëª…
            
        Returns:
            GPTë¡œ ìƒì„±ëœ ìš”ì•½
        """
        try:
            raw_text = self._combine_extracted_text(pages)
            
            if not raw_text.strip():
                return "âŒ ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # ë‚´ìš© ì „ì²´ ì¸ì‹ í”„ë¡¬í”„íŠ¸ (ìš”ì•½í•˜ì§€ ì•ŠìŒ)
            prompt = f"""
ë‹¤ìŒì€ PDF ë¬¸ì„œ "{file_name}"ì—ì„œ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì´ ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ë§ê³ , ì „ì²´ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ì¶”ì¶œëœ í…ìŠ¤íŠ¸:
{raw_text}  # ì „ì²´ í…ìŠ¤íŠ¸ í¬í•¨

ì •ë¦¬ ìš”êµ¬ì‚¬í•­:
1. âŒ ë‚´ìš©ì„ ì ˆëŒ€ ìš”ì•½í•˜ì§€ ë§ˆì„¸ìš” - ëª¨ë“  í˜ì´ì§€ì˜ ëª¨ë“  ì •ë³´ë¥¼ ë³´ì¡´í•´ì£¼ì„¸ìš”
2. âœ… ì „ì²´ í˜ì´ì§€ ì „ì²´ ë‚´ìš©ì„ ë¹ ëœ¨ë¦¬ì§€ ë§ê³  ëª¨ë‘ í¬í•¨í•´ì£¼ì„¸ìš”
3. âœ… ê° í˜ì´ì§€ë³„ë¡œ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì¬êµ¬ì„± (ì œëª©, ëª©ë¡, í‘œ ë“±)
4. âœ… **ëª¨ë“  í‘œ(í…Œì´ë¸”) ë°ì´í„°ëŠ” ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”**
5. âœ… **ë‹¤ìŒ í‘œë“¤ì„ íŠ¹íˆ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:**
   - ìœ„í—˜ë³´ì¥ ë° ë³´í—˜ê¸ˆ ì§€ê¸‰ í‘œ
   - í•´ì•½í™˜ê¸‰ê¸ˆ ì˜ˆì‹œí‘œ (ê²½ê³¼ê¸°ê°„ë³„) - **ë°˜ë“œì‹œ ì—°ë„ë³„/ê²½ê³¼ê¸°ê°„ë³„ ìƒì„¸ ë°ì´í„° í¬í•¨**
   - ê°±ì‹ ë‹´ë³´ ë³´í—˜ë£Œ ì˜ˆì‹œí‘œ
   - ëª¨ë“  ìˆ«ì, ê¸ˆì•¡, ë¹„ìœ¨ ë°ì´í„°ê°€ í¬í•¨ëœ í‘œ
   - **í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ ëª¨ë“  í‘œì™€ ìˆ˜ì¹˜ ë°ì´í„°**
6. âœ… OCR ì˜¤ë¥˜ë‚˜ ì˜¤íƒ€ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”
7. âœ… í˜ì´ì§€ë³„ë¡œ ì„¹ì…˜ì„ ëª…í™•íˆ êµ¬ë¶„í•´ì£¼ì„¸ìš”
8. âœ… ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì‚¬ìš© (## ì œëª©, ** ê°•ì¡°, - ëª©ë¡, | í‘œ |)
9. âœ… í•œêµ­ì–´ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ, ì˜ì–´/ìˆ«ìëŠ” ì›ë¬¸ ìœ ì§€
10. âœ… ì¤‘ìš”í•œ ì •ë³´ëŠ” êµµê²Œ í‘œì‹œí•´ì£¼ì„¸ìš”
11. âœ… ëª¨ë“  í˜ì´ì§€ì˜ ë‚´ìš©ì„ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í•´ì£¼ì„¸ìš”
12. âš ï¸  **ì¤‘ìš”**: ì „ì²´ í˜ì´ì§€ ëê¹Œì§€ ëª¨ë“  ë‚´ìš©ì„ ì™„ì„±í•´ì£¼ì„¸ìš”. ì¤‘ê°„ì— ëŠì§€ ë§ˆì„¸ìš”!

í‘œ ë°ì´í„° ì˜ˆì‹œ:

**ìœ„í—˜ë³´ì¥í‘œ:**
| ë‹´ë³´ëª… | ë³´ì¥ê¸ˆì•¡ | ë³´í—˜ë£Œ(ì¶œìƒì „) | ë³´í—˜ë£Œ(ì¶œìƒí›„) | ë¹„ê³  |
|--------|----------|----------------|----------------|------|
| ìƒí•´í›„ìœ ì¥í•´ | 1ì–µì› | 350ì› | 1,820ì› | 3~100% |
| ì•”ì§„ë‹¨ | 1ì–µì› | 2,230ì› | 5,230ì› | - |

**í•´ì•½í™˜ê¸‰ê¸ˆ ì˜ˆì‹œí‘œ:**
| ê²½ê³¼ê¸°ê°„ | ë‚©ì…ë³´í—˜ë£Œ | í•´ì•½í™˜ê¸‰ê¸ˆ | í™˜ê¸‰ë¥  |
|----------|------------|------------|-------|
| 03ê°œì›” | 246,870ì› | 0ì› | 0.0% |
| 01ë…„ | 987,480ì› | 0ì› | 0.0% |
| 30ë…„01ê°œì›” | 30,065,340ì› | 14,806,968ì› | 49.3% |

**âš ï¸ í•´ì•½í™˜ê¸‰ê¸ˆ í‘œ ì¶”ì¶œ ì‹œ ì£¼ì˜ì‚¬í•­:**
- ì—°ë„ë³„/ê²½ê³¼ê¸°ê°„ë³„ ëª¨ë“  ë°ì´í„°ë¥¼ ë¹ ëœ¨ë¦¬ì§€ ë§ê³  í¬í•¨
- í‘œ êµ¬ì¡°ê°€ ê¹¨ì ¸ë„ ìˆ«ì ë°ì´í„°ëŠ” ë°˜ë“œì‹œ ë³´ì¡´
- "í•´ì•½í™˜ê¸‰ê¸ˆ", "í™˜ê¸‰ê¸ˆ", "í•´ì•½" ê´€ë ¨ ëª¨ë“  í‘œì™€ ìˆ˜ì¹˜ ì¶”ì¶œ

**ê°±ì‹ ë‹´ë³´ ë³´í—˜ë£Œ ì˜ˆì‹œí‘œ:**
| ë‹´ë³´ëª… | ê°±ì‹ ì£¼ê¸° | 0ì°¨(í˜„ì¬) | 1ì°¨ ë³´í—˜ë£Œ | ì¦ê°€ìœ¨ | 2ì°¨ ë³´í—˜ë£Œ | ì¦ê°€ìœ¨ |
|--------|----------|-----------|------------|--------|------------|--------|
| ë…ê°ì¹˜ë£Œë‹´ë³´ | 20ë…„ | 1,770ì› | 313ì› | -82.3% | 270ì› | -13.7% |
| í‘œì í•­ì•”ì•½ë¬¼ | 10ë…„ | 469ì› | 511ì› | 9.0% | 875ì› | 71.2% |

ê²°ê³¼ í˜•ì‹:
# PDF ì „ì²´ ë‚´ìš©: {file_name}

## ğŸ“‹ ë¬¸ì„œ ì •ë³´
[ë¬¸ì„œì˜ ê¸°ë³¸ ì •ë³´]

## ğŸ“„ ì „ì²´ ë‚´ìš©
[ëª¨ë“  ë‚´ìš©ì„ êµ¬ì¡°í™”í•˜ì—¬ í‘œì‹œ - ì ˆëŒ€ ìš”ì•½í•˜ì§€ ì•ŠìŒ]

### ğŸ“Š ìœ„í—˜ë³´ì¥ ë° ë³´í—˜ê¸ˆ ì§€ê¸‰ í‘œ
[ìœ„í—˜ë³´ì¥ ê´€ë ¨ ëª¨ë“  í‘œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬]

### ğŸ’° í•´ì•½í™˜ê¸‰ê¸ˆ ì˜ˆì‹œí‘œ
[ê²½ê³¼ê¸°ê°„ë³„ í•´ì•½í™˜ê¸‰ê¸ˆ í‘œë¥¼ ì™„ì „íˆ ì •ë¦¬]

### ğŸ”„ ê°±ì‹ ë‹´ë³´ ë³´í—˜ë£Œ ì˜ˆì‹œí‘œ  
[ê°±ì‹ ì°¨ìˆ˜ë³„ ë³´í—˜ë£Œ ë³€ë™ í‘œë¥¼ ì™„ì „íˆ ì •ë¦¬]

### ğŸ“‹ ê¸°íƒ€ ëª¨ë“  í‘œ ë°ì´í„°
[ë¬¸ì„œ ë‚´ ëª¨ë“  í‘œ í˜•íƒœ ë°ì´í„°ë¥¼ ë¹ ëœ¨ë¦¬ì§€ ì•Šê³  ì •ë¦¬]
"""

            # Rate Limitì„ ê³ ë ¤í•œ ì•ˆì „í•œ API í˜¸ì¶œ
            messages = [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ PDF ë¬¸ì„œ ì •ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ë§ê³ , ëª¨ë“  ì •ë³´ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ì½ê¸° ì‰½ê²Œ êµ¬ì¡°í™”í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ]
            
            response = self._safe_api_call(
                messages=messages, 
                max_tokens=8000,  # 19í˜ì´ì§€ ì „ì²´ ì¶œë ¥ì„ ìœ„í•´ ëŒ€í­ í™•ëŒ€
                retries=3,
                delay=2
            )
            
            if response is None:
                # GPT ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ë¦¬ ì‹œë„
                logger.warning("GPT API ì‹¤íŒ¨, ê¸°ë³¸ í…ìŠ¤íŠ¸ í¬ë§·íŒ… ì‚¬ìš©")
                return self._fallback_formatting(pages, file_name)
            
            summary = response.choices[0].message.content.strip()
            
            # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            from datetime import datetime
            metadata = f"""ğŸ“„ PDF ìš”ì•½ ê²°ê³¼
{'='*50}

ğŸ“ íŒŒì¼ëª…: {file_name}
ğŸ“‘ í˜ì´ì§€ ìˆ˜: {len(pages)}
â° ìš”ì•½ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ¤– ìš”ì•½ ë°©ì‹: GPT API ì‚¬ìš©

{'='*50}

"""
            
            return metadata + summary
            
        except Exception as e:
            logger.error(f"GPT ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"âŒ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def summarize_content(self, pages: List[Dict[str, Any]], file_name: str) -> str:
        """
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½ (ì„ íƒì  ê¸°ëŠ¥)
        
        Args:
            pages: PDF í˜ì´ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            file_name: PDF íŒŒì¼ëª…
            
        Returns:
            GPTë¡œ ìƒì„±ëœ ìš”ì•½
        """
        try:
            raw_text = self._combine_extracted_text(pages)
            
            if not raw_text.strip():
                return "âŒ ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # ìš”ì•½ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¤ìŒ PDF ë¬¸ì„œì˜ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ë¬¸ì„œëª…: {file_name}
í˜ì´ì§€ ìˆ˜: {len(pages)}

ë‚´ìš©:
{raw_text}  # ì „ì²´ í…ìŠ¤íŠ¸ í¬í•¨

ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½
2. ì¤‘ìš”í•œ í‚¤ì›Œë“œì™€ ê°œë… í¬í•¨
3. êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì‘ì„±
4. í•œêµ­ì–´ ì‚¬ìš©
"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•µì‹¬ ë‚´ìš©ì„ ë†“ì¹˜ì§€ ì•Šê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"GPT ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"âŒ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _combine_extracted_text(self, pages: List[Dict[str, Any]]) -> str:
        """ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ í•©ì¹˜ê¸° (ì „ì²´ ë‚´ìš© ë³´ì¡´)"""
        all_text = ""
        
        # íƒ€ì… ì•ˆì „ì„± í™•ì¸
        if not isinstance(pages, list):
            logger.error(f"Expected list, got {type(pages)}")
            return ""
        
        total_pages = len(pages)
        logger.info(f"GPT í…ìŠ¤íŠ¸ ì¡°í•© ì‹œì‘: ì´ {total_pages} í˜ì´ì§€")
        
        for i, page in enumerate(pages):
            # ê° í˜ì´ì§€ê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
            if not isinstance(page, dict):
                logger.error(f"Page {i} is not dict: {type(page)}")
                continue
                
            page_num = page.get('page_number', i+1)
            text = page.get('text', '')
            ocr_text = page.get('ocr_text', '')
            
            # í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ í˜ì´ì§€ íŠ¹ë³„ í‘œì‹œ
            is_surrender_page = any(keyword in text for keyword in ['í•´ì•½í™˜ê¸‰ê¸ˆ', 'í™˜ê¸‰ê¸ˆ', 'ê²½ê³¼ê¸°ê°„'])
            page_marker = f"\n\n=== í˜ì´ì§€ {page_num}/{total_pages} {'[í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨]' if is_surrender_page else ''} ===\n"
            all_text += page_marker
            
            if is_surrender_page:
                logger.info(f"í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ í˜ì´ì§€ {page_num} GPT í…ìŠ¤íŠ¸ì— í¬í•¨")
            
            # ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ê°€ (ë” ë§ì€ ë‚´ìš© í¬í•¨)
            if text.strip():
                all_text += text.strip() + "\n"
            
            # OCR í…ìŠ¤íŠ¸ ì¶”ê°€ (êµ¬ë¶„í•˜ì—¬ í‘œì‹œ)
            if ocr_text.strip():
                if text.strip():
                    all_text += "\n[OCRë¡œ ì¶”ê°€ ì¶”ì¶œëœ í…ìŠ¤íŠ¸]\n"
                all_text += ocr_text.strip() + "\n"
            
            # í˜ì´ì§€ì— í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ê²½ìš° í‘œì‹œ
            if not text.strip() and not ocr_text.strip():
                all_text += "[ì´ í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤]\n"
        
        logger.info(f"ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(all_text)} ì, ì´ {total_pages} í˜ì´ì§€")
        return all_text
    
    def _create_formatting_prompt(self, raw_text: str, file_name: str, page_count: int) -> str:
        """GPT í¬ë§·íŒ…ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
ë‹¤ìŒì€ PDF "{file_name}"ì—ì„œ OCRë¡œ ì¶”ì¶œí•œ ì›ë³¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ë§ê³ , ì½ê¸° ì‰½ê²Œ ì •ë¦¬ë§Œ í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ì •ë³´:
- íŒŒì¼ëª…: {file_name}
- í˜ì´ì§€ ìˆ˜: {page_count}

ì›ë³¸ í…ìŠ¤íŠ¸:
{raw_text}  # ì „ì²´ í…ìŠ¤íŠ¸ í¬í•¨

ì •ë¦¬ ìš”êµ¬ì‚¬í•­:
1. ë‚´ìš©ì„ ì ˆëŒ€ ìš”ì•½í•˜ì§€ ë§ˆì„¸ìš” - ëª¨ë“  ì •ë³´ë¥¼ ë³´ì¡´
2. êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì¬êµ¬ì„± (ì œëª©, ëª©ë¡, í‘œ ë“±)
3. ì˜¤íƒ€ë‚˜ OCR ì˜¤ë¥˜ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •
4. ë¬¸ë‹¨ê³¼ ì„¹ì…˜ì„ ëª…í™•íˆ êµ¬ë¶„
5. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì‚¬ìš© (ì œëª©: ##, ëª©ë¡: -, ê°•ì¡°: **)
6. ì¤‘ìš”í•œ ì •ë³´ëŠ” êµµê²Œ í‘œì‹œ
7. í•œêµ­ì–´ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ, ì˜ì–´ëŠ” ì›ë¬¸ ìœ ì§€

ê²°ê³¼ í˜•ì‹:
# ë¬¸ì„œ ì œëª© (íŒŒì¼ëª… ê¸°ë°˜)

## ê°œìš”
[ë¬¸ì„œì˜ ê¸°ë³¸ ì •ë³´]

## ì£¼ìš” ë‚´ìš©
[êµ¬ì¡°í™”ëœ ì „ì²´ ë‚´ìš©]
"""
    
    def _add_document_metadata(self, formatted_text: str, file_name: str, page_count: int) -> str:
        """ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
        from datetime import datetime
        
        metadata = f"""ğŸ“„ PDF ë¬¸ì„œ ì •ë¦¬ ê²°ê³¼
{'='*50}

ğŸ“ íŒŒì¼ëª…: {file_name}
ğŸ“‘ í˜ì´ì§€ ìˆ˜: {page_count}
â° ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ¤– ì •ë¦¬ ë°©ì‹: GPT API ì‚¬ìš©

{'='*50}

"""
        return metadata + formatted_text
    
    def _fallback_formatting(self, pages: List[Dict[str, Any]], file_name: str) -> str:
        """GPT ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í¬ë§·íŒ…"""
        from datetime import datetime
        
        result = f"""ğŸ“„ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼ (ê¸°ë³¸ ëª¨ë“œ)
{'='*50}

ğŸ“ íŒŒì¼ëª…: {file_name}
ğŸ“‘ í˜ì´ì§€ ìˆ˜: {len(pages)}
â° ì²˜ë¦¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
âš ï¸  GPT API ì‚¬ìš© ë¶ˆê°€ - ê¸°ë³¸ í¬ë§· ì ìš©

{'='*50}

"""
        
        # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ê°€
        for i, page in enumerate(pages):
            # ê° í˜ì´ì§€ê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
            if not isinstance(page, dict):
                continue
                
            page_num = page.get('page_number', i+1)
            text = page.get('text', '')
            ocr_text = page.get('ocr_text', '')
            
            result += f"\n## í˜ì´ì§€ {page_num}\n"
            result += "-" * 20 + "\n"
            
            if text.strip():
                result += text.strip() + "\n\n"
            
            if ocr_text.strip():
                result += "**[OCR í…ìŠ¤íŠ¸]**\n"
                result += ocr_text.strip() + "\n\n"
        
        return result
    
    def analyze_for_comparison(self, pages: List[Dict[str, Any]], file_name: str) -> str:
        """
        ìƒí’ˆ ë¹„êµìš© í•µì‹¬ ì •ë³´ ì¶”ì¶œ ë° ë¶„ì„
        
        Args:
            pages: PDF í˜ì´ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            file_name: PDF íŒŒì¼ëª…
            
        Returns:
            ë¹„êµ ë¶„ì„ì— íŠ¹í™”ëœ êµ¬ì¡°í™”ëœ ì •ë³´
        """
        try:
            raw_text = self._combine_extracted_text(pages)
            
            if not raw_text.strip():
                return "âŒ ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # í† í° ì œí•œ ê³ ë ¤í•œ ìŠ¤ë§ˆíŠ¸ ì ˆë‹¨ (ë¹„êµ ë¶„ì„ìš© - ì „ì²´ ë³´ì¡´)
            smart_text = self._smart_truncate_text(raw_text, max_input_tokens=80000)
            
            # ë¹„êµ ë¶„ì„ìš© íŠ¹í™” í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¤ìŒì€ ë³´í—˜ ìƒí’ˆ ë¬¸ì„œ "{file_name}"ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ì´ ìƒí’ˆì„ ë‹¤ë¥¸ ìƒí’ˆê³¼ ë¹„êµí•˜ê¸° ìœ„í•œ í•µì‹¬ ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì¶”ì¶œëœ í…ìŠ¤íŠ¸:
{smart_text}

ë¶„ì„ ìš”êµ¬ì‚¬í•­:
1. **ìƒí’ˆ ê¸°ë³¸ ì •ë³´**
   - ìƒí’ˆëª…, ìƒí’ˆ ì½”ë“œ
   - ìƒí’ˆ íƒ€ì… (ì–´ë¦°ì´ë³´í—˜, ì¢…í•©ë³´í—˜, ì•”ë³´í—˜ ë“±)
   - ë³´í—˜ íšŒì‚¬ëª…

2. **ë³´í—˜ë£Œ ì •ë³´** ğŸš¨ ì¤‘ìš”: ëª¨ë“  ê¸ˆì•¡ì€ ì›ë³¸ ë¬¸ì„œì˜ ì •í™•í•œ ìˆ«ìë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”
   - ì›” ë³´í—˜ë£Œ (ì˜ˆ: 92,540ì›ì²˜ëŸ¼ ì›ë³¸ ê·¸ëŒ€ë¡œ, ì ˆëŒ€ ë°˜ì˜¬ë¦¼í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”)
   - ë‚©ì… ë°©ì‹ (ì›”ë‚©, ì—°ë‚© ë“±)
   - ë‚©ì… ê¸°ê°„
   
   âš ï¸ ê¸ˆì•¡ í‘œê¸° ì£¼ì˜ì‚¬í•­:
   - 92,540ì›ì€ ê·¸ëŒ€ë¡œ 92,540ì›ìœ¼ë¡œ í‘œê¸°
   - ì ˆëŒ€ 92,000ì›ì´ë‚˜ 93,000ì›ìœ¼ë¡œ ë°˜ì˜¬ë¦¼í•˜ì§€ ì•Šê¸°
   - ëª¨ë“  ìˆ«ìëŠ” ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ë°œê²¬í•œ ê·¸ëŒ€ë¡œ ì •í™•íˆ ë³µì‚¬

3. **í•µì‹¬ ë³´ì¥ ë‚´ìš©**
   - ê¸°ë³¸ ë³´ì¥ (ì£¼ê³„ì•½)
   - ì£¼ìš” íŠ¹ì•½ ë³´ì¥ (ìƒìœ„ 5ê°œ)
   - ë³´ì¥ ê¸ˆì•¡ ë° ë²”ìœ„

4. **ë¹„êµ ìš°ìœ„ ìš”ì†Œ**
   - ì´ ìƒí’ˆë§Œì˜ ë…íŠ¹í•œ ë³´ì¥
   - íƒ€ ìƒí’ˆ ëŒ€ë¹„ ìœ ë¦¬í•œ ì 
   - ë³´í—˜ë£Œ ê²½ìŸë ¥

5. **í•´ì•½/í™˜ê¸‰ ì •ë³´**
   - í™˜ê¸‰ ë°©ì‹ (ë¬´í•´ì§€í™˜ê¸‰í˜•, ì €í•´ì§€í™˜ê¸‰í˜• ë“±)
   - ë§Œê¸° í™˜ê¸‰ë¥  ë˜ëŠ” ì¡°ê±´

6. **ëŒ€ìƒ ê³ ê°**
   - ì£¼ìš” íƒ€ê²Ÿ ì—°ë ¹ì¸µ
   - ì¶”ì²œ ìƒí™©

ê²°ê³¼ í˜•ì‹:
# ğŸ·ï¸ ìƒí’ˆ ë¹„êµ ë¶„ì„: {file_name}

## ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ìƒí’ˆëª…**: [ì •í™•í•œ ìƒí’ˆëª…]
- **ìƒí’ˆì½”ë“œ**: [ì½”ë“œ]
- **ìƒí’ˆíƒ€ì…**: [ì¹´í…Œê³ ë¦¬]
- **íšŒì‚¬**: [ë³´í—˜ì‚¬ëª…]

## ğŸ’° ë³´í—˜ë£Œ ì •ë³´ ğŸš¨ ìˆ«ì ë³€ê²½ ì ˆëŒ€ ê¸ˆì§€
- **ì›”ë³´í—˜ë£Œ**: [ì›ë³¸ ë¬¸ì„œì˜ ì •í™•í•œ ê¸ˆì•¡ - ì˜ˆ: 92,540ì›]
- **ë‚©ì…ë°©ì‹**: [ë°©ì‹]
- **ë‚©ì…ê¸°ê°„**: [ê¸°ê°„]

ğŸ’¡ **ê¸ˆì•¡ í‘œê¸° ì›ì¹™**: 
- ë¬¸ì„œì—ì„œ ì°¾ì€ ì •í™•í•œ ê¸ˆì•¡ì„ ê·¸ëŒ€ë¡œ í‘œê¸°
- ì ˆëŒ€ ë°˜ì˜¬ë¦¼í•˜ì§€ ì•ŠìŒ (ì˜ˆ: 92,540ì› â†’ 92,000ì› ë³€ê²½ ê¸ˆì§€)

## ğŸ›¡ï¸ í•µì‹¬ ë³´ì¥
### ê¸°ë³¸ë³´ì¥ (ì£¼ê³„ì•½)
- [ì£¼ê³„ì•½ ë‚´ìš© ë° ê¸ˆì•¡]

### ì£¼ìš” íŠ¹ì•½ TOP 5
1. [íŠ¹ì•½ëª…] - [ë³´ì¥ê¸ˆì•¡] - [íŠ¹ì§•]
2. [íŠ¹ì•½ëª…] - [ë³´ì¥ê¸ˆì•¡] - [íŠ¹ì§•]
3. [íŠ¹ì•½ëª…] - [ë³´ì¥ê¸ˆì•¡] - [íŠ¹ì§•]
4. [íŠ¹ì•½ëª…] - [ë³´ì¥ê¸ˆì•¡] - [íŠ¹ì§•]
5. [íŠ¹ì•½ëª…] - [ë³´ì¥ê¸ˆì•¡] - [íŠ¹ì§•]

## â­ ê²½ìŸ ìš°ìœ„
- **ë…íŠ¹í•œ ë³´ì¥**: [ì°¨ë³„í™” ìš”ì†Œ]
- **ë³´í—˜ë£Œ ê²½ìŸë ¥**: [ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼]
- **íŠ¹í™” ì˜ì—­**: [ê°•ì  ë¶„ì•¼]

## ğŸ’ í•´ì•½/í™˜ê¸‰
- **í™˜ê¸‰ë°©ì‹**: [ë°©ì‹]
- **ë§Œê¸°ì¡°ê±´**: [ì¡°ê±´]

## ğŸ¯ ì¶”ì²œ ëŒ€ìƒ
- **ì£¼ìš” ê³ ê°**: [íƒ€ê²Ÿì¸µ]
- **ì¶”ì²œ ìƒí™©**: [ì–¸ì œ ìœ ë¦¬í•œì§€]

## ğŸ“Š ë¹„êµ ì ìˆ˜ (5ì  ë§Œì )
- **ë³´í—˜ë£Œ ê²½ìŸë ¥**: â­â­â­â­â­
- **ë³´ì¥ ë‹¤ì–‘ì„±**: â­â­â­â­â­  
- **ë³´ì¥ ì¶©ì‹¤ë„**: â­â­â­â­â­
- **í•´ì•½ ì¡°ê±´**: â­â­â­â­â­
"""

            messages = [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë³´í—˜ìƒí’ˆ ë¹„êµ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìƒí’ˆì˜ í•µì‹¬ ê²½ìŸë ¥ê³¼ ì°¨ë³„í™” ìš”ì†Œë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì—¬ ë¹„êµì— ìµœì í™”ëœ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”. ğŸš¨ ì¤‘ìš”: ëª¨ë“  ê¸ˆì•¡ê³¼ ìˆ«ìëŠ” ì›ë³¸ ë¬¸ì„œì˜ ì •í™•í•œ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ì ˆëŒ€ ë°˜ì˜¬ë¦¼í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ]
            
            response = self._safe_api_call(
                messages=messages,
                max_tokens=6000,  # ë” ìƒì„¸í•œ ë¶„ì„ì„ ìœ„í•´ ì¦ê°€
                retries=3,
                delay=2
            )
            
            if response is None:
                # GPT ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ë¦¬ ì‹œë„
                logger.warning("GPT API ì‹¤íŒ¨, ê¸°ë³¸ í…ìŠ¤íŠ¸ í¬ë§·íŒ… ì‚¬ìš©")
                return self._fallback_formatting(pages, file_name)
            
            analysis = response.choices[0].message.content.strip()
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            from datetime import datetime
            metadata = f"""ğŸ“Š ìƒí’ˆ ë¹„êµ ë¶„ì„ ê²°ê³¼
{'='*50}

ğŸ“ íŒŒì¼ëª…: {file_name}
ğŸ“‘ í˜ì´ì§€ ìˆ˜: {len(pages)}
â° ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ¯ ë¶„ì„ ëª©ì : ìƒí’ˆ ë¹„êµìš© í•µì‹¬ ì •ë³´ ì¶”ì¶œ

{'='*50}

"""
            
            return metadata + analysis
            
        except Exception as e:
            logger.error(f"ìƒí’ˆ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"âŒ ë¹„êµ ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def analyze_products_comparison(self, pages1: List[Dict[str, Any]], file1_name: str, 
                                    pages2: List[Dict[str, Any]], file2_name: str, 
                                    custom_prompt: str = "") -> str:
        """
        ë‘ ë³´í—˜ìƒí’ˆì˜ ì§ì ‘ì ì¸ ë¹„êµ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            pages1: ì²« ë²ˆì§¸ ìƒí’ˆ í˜ì´ì§€ ë°ì´í„°
            file1_name: ì²« ë²ˆì§¸ ìƒí’ˆ íŒŒì¼ëª…
            pages2: ë‘ ë²ˆì§¸ ìƒí’ˆ í˜ì´ì§€ ë°ì´í„°
            file2_name: ë‘ ë²ˆì§¸ ìƒí’ˆ íŒŒì¼ëª…
            
        Returns:
            ë‘ ìƒí’ˆì˜ ì¢…í•©ì ì¸ ë¹„êµ ë¶„ì„ ê²°ê³¼
        """
        try:
            # ë‘ ìƒí’ˆì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text1 = self._combine_extracted_text(pages1)
            text2 = self._combine_extracted_text(pages2)
            
            if not text1.strip() or not text2.strip():
                return "âŒ ë¹„êµí•  í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            
            # ê¸ˆì•¡ ë‹¨ìœ„ ì •ê·œí™” (ë‘ ìƒí’ˆ ëª¨ë‘)
            normalized_text1 = self._normalize_currency_units(text1)
            normalized_text2 = self._normalize_currency_units(text2)
            
            # í† í° ì œí•œ ê³ ë ¤í•œ ìŠ¤ë§ˆíŠ¸ ì ˆë‹¨ (ë‘ ìƒí’ˆ ëª¨ë‘)
            smart_text1 = self._smart_truncate_text(normalized_text1, max_input_tokens=40000)
            smart_text2 = self._smart_truncate_text(normalized_text2, max_input_tokens=40000)
            
            pages1_count = len(pages1)
            pages2_count = len(pages2)
            
            # í‘œ ë°ì´í„° ì¶”ì¶œ ë° ì£¼ì…
            table_data1 = self._extract_table_data_from_pages(pages1)
            table_data2 = self._extract_table_data_from_pages(pages2)
            
            # ì¢…í•© ë¹„êµ ë¶„ì„ í”„ë¡¬í”„íŠ¸
            user_instruction = ""
            if custom_prompt:
                user_instruction = f"""
ğŸš¨ **ì‚¬ìš©ì íŠ¹ë³„ ìš”ì²­ì‚¬í•­**:
{custom_prompt}

ìœ„ ìš”ì²­ì‚¬í•­ì„ ë°˜ë“œì‹œ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.
"""
            
            prompt = f"""
ì•„ë˜ì—ëŠ” ë‘ ê°€ì§€ ë³´í—˜ ìƒí’ˆì˜ ë³´ì¥ ë‚´ì—­ì´ ìˆìŠµë‹ˆë‹¤. 
ì´ ë‘ ìƒí’ˆì„ ê³ ê°ì˜ ì…ì¥ì—ì„œ ì‰½ê²Œ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
{user_instruction}

**ğŸ“Š í‘œ ë°ì´í„° (ì •í™•í•œ ìˆ˜ì¹˜ ë¹„êµìš©)**:
ìƒí’ˆ A í‘œ ë°ì´í„°: {table_data1}
ìƒí’ˆ B í‘œ ë°ì´í„°: {table_data2}

**ìƒí’ˆ A**: {file1_name}
í˜ì´ì§€ ìˆ˜: {pages1_count}
ì¶”ì¶œëœ í…ìŠ¤íŠ¸:
{smart_text1}

**ìƒí’ˆ B**: {file2_name}  
í˜ì´ì§€ ìˆ˜: {pages2_count}
ì¶”ì¶œëœ í…ìŠ¤íŠ¸:
{smart_text2}

[ì¶œë ¥ ì§€ì¹¨]

1. **ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ**
   - ìƒí’ˆëª…, ìƒí’ˆì½”ë“œ, ìƒí’ˆíƒ€ì…, ë³´í—˜íšŒì‚¬ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”
   - ğŸš¨ **ë³´í—˜ë£Œ ì •ë³´**: ëª¨ë“  ê¸ˆì•¡ì€ ì›ë³¸ ë¬¸ì„œì˜ ì •í™•í•œ ìˆ«ìë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”
     (ì˜ˆ: 92,540ì›ì€ ì ˆëŒ€ 92,000ì›ìœ¼ë¡œ ë°˜ì˜¬ë¦¼í•˜ì§€ ë§ˆì„¸ìš”)
   - ğŸ’° **ê¸ˆì•¡ ë‹¨ìœ„ í†µì¼**: ëª¨ë“  ê¸ˆì•¡ì€ ì› ë‹¨ìœ„ë¡œ í†µì¼í•˜ì—¬ ë¹„êµí•˜ì„¸ìš”
     (ì²œì›, ë§Œì›, ì–µì› ë“±ì€ ëª¨ë‘ ì› ë‹¨ìœ„ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ)

2. **ë³´ì¥ í•­ëª© ìë™ ì‹ë³„ ë° ë§¤ì¹­**
   - ë‘ ë¬¸ì„œì—ì„œ 'ë³´ì¥ í•­ëª©'ì„ ìŠ¤ìŠ¤ë¡œ ì‹ë³„í•˜ì„¸ìš” 
     (ì˜ˆ: ìˆ˜ìˆ ë³´ì¥, íŠ¹ì •ì§ˆë³‘ë³´ì¥, ì…ì›ë³´ì¥, ë‚©ì…ë©´ì œ, ë¹„ê¸‰ì—¬ì¹˜ë£Œ, ì•”ë³´ì¥, ë‡Œí˜ˆê´€ì§ˆí™˜ë³´ì¥ ë“±)
   - ë¬¸ì„œë§ˆë‹¤ í•­ëª© ì´ë¦„ì´ë‚˜ êµ¬ì„±ì´ ë‹¬ë¼ë„ ê°™ì€ ì˜ë¯¸ë¼ë©´ ê°™ì€ ì¹´í…Œê³ ë¦¬ë¡œ ë¬¶ì–´ ë¹„êµí•˜ì„¸ìš”
   - í•œìª½ ìƒí’ˆì—ë§Œ ì¡´ì¬í•˜ëŠ” í•­ëª©ì€ 'í•´ë‹¹ ì—†ìŒ'ìœ¼ë¡œ í‘œì‹œí•˜ì„¸ìš”

3. **ì „ë¬¸ìš©ì–´ ê³ ê° ì¹œí™”ì  í•´ì„**
   - ì „ë¬¸ ìš©ì–´ê°€ ìˆìœ¼ë©´ ê°„ë‹¨í•œ ì„¤ëª…ì„ ê´„í˜¸ ì•ˆì— ì¶”ê°€í•´ ì£¼ì„¸ìš”
     (ì˜ˆ: 'ë‚©ì…ë©´ì œ(íŠ¹ì • ì¡°ê±´ ì¶©ì¡± ì‹œ ë³´í—˜ë£Œ ë‚©ì…ì„ ë©´ì œë°›ëŠ” ì œë„)')
   - ë³´í—˜ ë¹„ì „ë¬¸ê°€ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”

ê²°ê³¼ í˜•ì‹:

# ğŸ·ï¸ 2ê°œ ìƒí’ˆ ë¹„êµ ë¶„ì„

## ğŸ“Š ìƒí’ˆ A ë¶„ì„

### ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ìƒí’ˆëª…**: [ì •í™•í•œ ìƒí’ˆëª…]
- **ìƒí’ˆì½”ë“œ**: [ì½”ë“œ]
- **ìƒí’ˆíƒ€ì…**: [ì¹´í…Œê³ ë¦¬]
- **íšŒì‚¬**: [ë³´í—˜ì‚¬ëª…]

### ğŸ’° ë³´í—˜ë£Œ ì •ë³´ ğŸš¨ ìˆ«ì ë³€ê²½ ì ˆëŒ€ ê¸ˆì§€
- **ì›”ë³´í—˜ë£Œ**: [ì›ë³¸ ë¬¸ì„œì˜ ì •í™•í•œ ê¸ˆì•¡ - ì˜ˆ: 92,540ì›]
- **ë‚©ì…ë°©ì‹**: [ë°©ì‹]
- **ë‚©ì…ê¸°ê°„**: [ê¸°ê°„]

### ğŸ›¡ï¸ í•µì‹¬ ë³´ì¥ ë‚´ìš©
| ë³´ì¥ í•­ëª© | ë³´ì¥ ë‚´ìš© | ë³´ì¥ ê¸ˆì•¡/íšŸìˆ˜ |
|-----------|-----------|----------------|
| [í•­ëª©1] | [êµ¬ì²´ì  ë‚´ìš©] | [ê¸ˆì•¡/íšŸìˆ˜] |
| [í•­ëª©2] | [êµ¬ì²´ì  ë‚´ìš©] | [ê¸ˆì•¡/íšŸìˆ˜] |
| [í•­ëª©3] | [êµ¬ì²´ì  ë‚´ìš©] | [ê¸ˆì•¡/íšŸìˆ˜] |

### â­ ê²½ìŸ ìš°ìœ„ ìš”ì†Œ
- **ë…íŠ¹í•œ ë³´ì¥**: [ì°¨ë³„í™” ìš”ì†Œ]
- **ë³´í—˜ë£Œ ê²½ìŸë ¥**: [ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼]
- **íŠ¹í™” ì˜ì—­**: [ê°•ì  ë¶„ì•¼]

---

## ğŸ“Š ìƒí’ˆ B ë¶„ì„

### ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ìƒí’ˆëª…**: [ì •í™•í•œ ìƒí’ˆëª…]
- **ìƒí’ˆì½”ë“œ**: [ì½”ë“œ]  
- **ìƒí’ˆíƒ€ì…**: [ì¹´í…Œê³ ë¦¬]
- **íšŒì‚¬**: [ë³´í—˜ì‚¬ëª…]

### ğŸ’° ë³´í—˜ë£Œ ì •ë³´ ğŸš¨ ìˆ«ì ë³€ê²½ ì ˆëŒ€ ê¸ˆì§€
- **ì›”ë³´í—˜ë£Œ**: [ì›ë³¸ ë¬¸ì„œì˜ ì •í™•í•œ ê¸ˆì•¡ - ì˜ˆ: 69,000ì›]
- **ë‚©ì…ë°©ì‹**: [ë°©ì‹]
- **ë‚©ì…ê¸°ê°„**: [ê¸°ê°„]

### ğŸ›¡ï¸ í•µì‹¬ ë³´ì¥ ë‚´ìš©
| ë³´ì¥ í•­ëª© | ë³´ì¥ ë‚´ìš© | ë³´ì¥ ê¸ˆì•¡/íšŸìˆ˜ |
|-----------|-----------|----------------|
| [í•­ëª©1] | [êµ¬ì²´ì  ë‚´ìš©] | [ê¸ˆì•¡/íšŸìˆ˜] |
| [í•­ëª©2] | [êµ¬ì²´ì  ë‚´ìš©] | [ê¸ˆì•¡/íšŸìˆ˜] |
| [í•­ëª©3] | [êµ¬ì²´ì  ë‚´ìš©] | [ê¸ˆì•¡/íšŸìˆ˜] |

### â­ ê²½ìŸ ìš°ìœ„ ìš”ì†Œ
- **ë…íŠ¹í•œ ë³´ì¥**: [ì°¨ë³„í™” ìš”ì†Œ]
- **ë³´í—˜ë£Œ ê²½ìŸë ¥**: [ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼]
- **íŠ¹í™” ì˜ì—­**: [ê°•ì  ë¶„ì•¼]

---

## ğŸ” í•µì‹¬ ë¹„êµ ë¶„ì„

### ğŸ“Š ë³´ì¥ í•­ëª©ë³„ ìƒì„¸ ë¹„êµí‘œ
| ë³´ì¥ í•­ëª© | ìƒí’ˆ A | ìƒí’ˆ B | ì°¨ì´ì  ë° ìš°ìœ„ |
|-----------|--------|--------|----------------|
| [ê³µí†µí•­ëª©1] | [Aì˜ ë³´ì¥ë‚´ìš©] | [Bì˜ ë³´ì¥ë‚´ìš©] | [êµ¬ì²´ì  ì°¨ì´ì ] |
| [ê³µí†µí•­ëª©2] | [Aì˜ ë³´ì¥ë‚´ìš©] | [Bì˜ ë³´ì¥ë‚´ìš©] | [êµ¬ì²´ì  ì°¨ì´ì ] |
| [Aë§Œì˜ í•­ëª©] | [Aì˜ ë³´ì¥ë‚´ìš©] | í•´ë‹¹ ì—†ìŒ | [Aì˜ ë…ì  ì¥ì ] |
| [Bë§Œì˜ í•­ëª©] | í•´ë‹¹ ì—†ìŒ | [Bì˜ ë³´ì¥ë‚´ìš©] | [Bì˜ ë…ì  ì¥ì ] |

### ğŸ’¡ ê³ ê° ê´€ì  í•µì‹¬ ì°¨ì´ì 
1. **ë³´í—˜ë£Œ ë¹„êµ**: [êµ¬ì²´ì ì¸ ì›”ë³´í—˜ë£Œ ì°¨ì´ ë° ê°€ì„±ë¹„ ë¶„ì„]
2. **ë³´ì¥ ë²”ìœ„**: [ì–´ëŠ ìƒí’ˆì´ ë” í­ë„“ê²Œ/ê¹Šì´ ìˆê²Œ ë³´ì¥í•˜ëŠ”ì§€]
3. **ë…ì  ë³´ì¥**: [ê° ìƒí’ˆë§Œì˜ íŠ¹ë³„í•œ ë³´ì¥ ë‚´ìš©]
4. **ê³ ê° ìœ í˜•ë³„ ì¶”ì²œ**: [ì–´ë–¤ ê³ ê°ì—ê²Œ ì–´ë–¤ ìƒí’ˆì´ ë” ì í•©í•œì§€]

### ğŸ¯ ìƒí™©ë³„ ì¶”ì²œ ê°€ì´ë“œ
- **20-30ëŒ€ ì Šì€ì¸µ**: [ì¶”ì²œ ìƒí’ˆê³¼ ì´ìœ ]
- **30-40ëŒ€ ê°€ì¡±ì¸µ**: [ì¶”ì²œ ìƒí’ˆê³¼ ì´ìœ ]  
- **50ëŒ€+ ì¤‘ì¥ë…„ì¸µ**: [ì¶”ì²œ ìƒí’ˆê³¼ ì´ìœ ]
- **ë³´í—˜ë£Œ ì ˆì•½ ìš°ì„ **: [ì¶”ì²œ ìƒí’ˆê³¼ ì´ìœ ]
- **ë³´ì¥ ì¶©ì‹¤ë„ ìš°ì„ **: [ì¶”ì²œ ìƒí’ˆê³¼ ì´ìœ ]

âš ï¸ **ì¤‘ìš” ì£¼ì˜ì‚¬í•­**: 
- ëª¨ë“  ê¸ˆì•¡ì€ ì›ë³¸ ë¬¸ì„œì˜ ì •í™•í•œ ìˆ«ìë¥¼ ê·¸ëŒ€ë¡œ í‘œê¸°
- ì ˆëŒ€ ë°˜ì˜¬ë¦¼í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ
- ì „ë¬¸ìš©ì–´ëŠ” ê´„í˜¸ ì•ˆì— ì‰¬ìš´ ì„¤ëª… ì¶”ê°€
- í•­ëª© ëˆ„ë½ ì—†ì´ ëª¨ë“  ë³´ì¥ ë‚´ì—­ ë°˜ì˜
"""

            messages = [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë³´í—˜ìƒí’ˆ ë¹„êµ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‘ ìƒí’ˆì„ ê³ ê° ê´€ì ì—ì„œ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì²´ê³„ì ìœ¼ë¡œ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”. ğŸš¨ ì¤‘ìš”: ëª¨ë“  ê¸ˆì•¡ê³¼ ìˆ«ìëŠ” ì›ë³¸ ë¬¸ì„œì˜ ì •í™•í•œ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ì ˆëŒ€ ë°˜ì˜¬ë¦¼í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”. ì „ë¬¸ìš©ì–´ëŠ” ê³ ê°ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ]
            
            response = self._safe_api_call(
                messages=messages,
                max_tokens=8000,  # ì¢…í•© ë¹„êµ ë¶„ì„ì„ ìœ„í•´ ë” í° í† í° í• ë‹¹
                retries=3,
                delay=2
            )
            
            if response is None:
                # GPT ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¡°í•©
                logger.warning("GPT API ì‹¤íŒ¨, ê¸°ë³¸ ê°œë³„ ë¶„ì„ ì¡°í•© ì‚¬ìš©")
                return self._fallback_comparison(pages1, file1_name, pages2, file2_name)
            
            analysis = response.choices[0].message.content.strip()
            
            # ë””ë²„ê¹…: GPT ì‘ë‹µ ë¡œê¹…
            logger.info(f"ğŸ“Š GPT ì‘ë‹µ ìƒ˜í”Œ (ì²˜ìŒ 500ì): {analysis[:500]}")
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            from datetime import datetime
            metadata = f"""ğŸ” ë³´í—˜ìƒí’ˆ ì¢…í•© ë¹„êµ ë¶„ì„ ê²°ê³¼
{'='*60}

ğŸ“ ìƒí’ˆ A: {file1_name} ({pages1_count}í˜ì´ì§€)
ğŸ“ ìƒí’ˆ B: {file2_name} ({pages2_count}í˜ì´ì§€)
â° ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ¯ ë¶„ì„ ëª©ì : ê³ ê° ì¹œí™”ì  ì¢…í•© ë¹„êµ ë¶„ì„

{'='*60}

"""
            
            return metadata + analysis
            
        except Exception as e:
            logger.error(f"ì¢…í•© ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"âŒ ì¢…í•© ë¹„êµ ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _fallback_comparison(self, pages1: List[Dict[str, Any]], file1_name: str,
                           pages2: List[Dict[str, Any]], file2_name: str) -> str:
        """GPT ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¹„êµ í˜•íƒœë¡œ ì¡°í•©"""
        try:
            # ê°œë³„ ë¶„ì„ ìˆ˜í–‰
            analysis1 = self.analyze_for_comparison(pages1, file1_name)
            analysis2 = self.analyze_for_comparison(pages2, file2_name)
            
            return f"""# ğŸ” ê¸°ë³¸ ë¹„êµ ë¶„ì„ (GPT ë¶„ì„ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´)

## ğŸ“Š ìƒí’ˆ A ë¶„ì„
{analysis1}

---

## ğŸ“Š ìƒí’ˆ B ë¶„ì„  
{analysis2}

---

## âš ï¸ ì•Œë¦¼
GPT ë¹„êµ ë¶„ì„ì— ì‹¤íŒ¨í•˜ì—¬ ê¸°ë³¸ ê°œë³„ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
ìƒì„¸í•œ ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
"""
            
        except Exception as e:
            logger.error(f"Fallback ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"âŒ ë¹„êµ ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {str(e)}"

    def analyze_surrender_value(self, pages: List[Dict[str, Any]], file_name: str) -> str:
        """
        í•´ì•½í™˜ê¸‰ê¸ˆ ì •ë³´ë¥¼ íŠ¹í™”í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            pages: PDF í˜ì´ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            file_name: PDF íŒŒì¼ëª…
            
        Returns:
            í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ ìƒì„¸ ì •ë³´
        """
        try:
            raw_text = self._combine_extracted_text(pages)
            
            if not raw_text.strip():
                return "âŒ ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§
            surrender_keywords = ['í•´ì•½í™˜ê¸‰ê¸ˆ', 'í™˜ê¸‰ê¸ˆ', 'í•´ì•½', 'í™˜ê¸‰', 'ê²½ê³¼ê¸°ê°„', 'ë‚©ì…ë³´í—˜ë£Œ']
            surrender_text = self._extract_surrender_related_text(raw_text, surrender_keywords)
            
            if not surrender_text.strip():
                return "âŒ í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # í† í° ì œí•œ ê³ ë ¤í•œ ìŠ¤ë§ˆíŠ¸ ì ˆë‹¨
            smart_text = self._smart_truncate_text(surrender_text, max_input_tokens=40000)
            
            # í•´ì•½í™˜ê¸‰ê¸ˆ íŠ¹í™” í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¤ìŒì€ ë³´í—˜ ìƒí’ˆ "{file_name}"ì—ì„œ ì¶”ì¶œí•œ í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
í•´ì•½í™˜ê¸‰ê¸ˆì— ëŒ€í•œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

ì¶”ì¶œëœ í…ìŠ¤íŠ¸:
{smart_text}

ë¶„ì„ ìš”êµ¬ì‚¬í•­:
1. **í•´ì•½í™˜ê¸‰ê¸ˆ í‘œ ë°ì´í„° ì™„ì „ ì¶”ì¶œ**
   - ê²½ê³¼ê¸°ê°„ë³„ í•´ì•½í™˜ê¸‰ê¸ˆì•¡
   - ë‚©ì…ë³´í—˜ë£Œ ëŒ€ë¹„ í™˜ê¸‰ë¥ 
   - ì—°ë„ë³„ ìƒì„¸ ë°ì´í„°

2. **í‘œ êµ¬ì¡° ë³µì›**
   - ê¹¨ì§„ í‘œ êµ¬ì¡°ë¼ë„ ìˆ«ì ë°ì´í„°ëŠ” ë°˜ë“œì‹œ ë³´ì¡´
   - ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬
   - ëª¨ë“  ìˆ˜ì¹˜ ë°ì´í„° í¬í•¨

3. **ëˆ„ë½ëœ ì •ë³´ í™•ì¸**
   - í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ ëª¨ë“  í‘œì™€ ìˆ˜ì¹˜
   - ê²½ê³¼ê¸°ê°„ë³„ ìƒì„¸ ì •ë³´
   - í™˜ê¸‰ ì¡°ê±´ ë° ì œí•œì‚¬í•­

ê²°ê³¼ í˜•ì‹:
# ğŸ’° í•´ì•½í™˜ê¸‰ê¸ˆ ìƒì„¸ ë¶„ì„: {file_name}

## ğŸ“Š í•´ì•½í™˜ê¸‰ê¸ˆ í‘œ (ê²½ê³¼ê¸°ê°„ë³„)
| ê²½ê³¼ê¸°ê°„ | ë‚©ì…ë³´í—˜ë£Œ | í•´ì•½í™˜ê¸‰ê¸ˆ | í™˜ê¸‰ë¥  | ë¹„ê³  |
|----------|------------|------------|-------|------|
| [êµ¬ì²´ì  ë°ì´í„°] | [êµ¬ì²´ì  ê¸ˆì•¡] | [êµ¬ì²´ì  ê¸ˆì•¡] | [êµ¬ì²´ì  %] | [ì¡°ê±´] |

## ğŸ“ˆ í•´ì•½í™˜ê¸‰ê¸ˆ ë¶„ì„
- **ìµœì´ˆ í™˜ê¸‰ ì‹œì **: [êµ¬ì²´ì  ê²½ê³¼ê¸°ê°„]
- **ìµœëŒ€ í™˜ê¸‰ë¥ **: [êµ¬ì²´ì  %]
- **í™˜ê¸‰ ì¡°ê±´**: [êµ¬ì²´ì  ì¡°ê±´]

## âš ï¸ ì£¼ì˜ì‚¬í•­
- [í™˜ê¸‰ ì œí•œ ì¡°ê±´]
- [í•´ì•½ ì‹œ ì£¼ì˜ì‚¬í•­]
"""

            messages = [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë³´í—˜ í•´ì•½í™˜ê¸‰ê¸ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ ëª¨ë“  í‘œì™€ ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”. í‘œ êµ¬ì¡°ê°€ ê¹¨ì ¸ë„ ìˆ«ì ë°ì´í„°ëŠ” ë°˜ë“œì‹œ ë³´ì¡´í•˜ì—¬ ì œê³µí•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ]
            
            response = self._safe_api_call(
                messages=messages,
                max_tokens=6000,
                retries=3,
                delay=2
            )
            
            if response is None:
                return "âŒ í•´ì•½í™˜ê¸‰ê¸ˆ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            analysis = response.choices[0].message.content.strip()
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            from datetime import datetime
            metadata = f"""ğŸ’° í•´ì•½í™˜ê¸‰ê¸ˆ íŠ¹í™” ë¶„ì„ ê²°ê³¼
{'='*50}

ğŸ“ íŒŒì¼ëª…: {file_name}
ğŸ“‘ í˜ì´ì§€ ìˆ˜: {len(pages)}
â° ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ¯ ë¶„ì„ ëª©ì : í•´ì•½í™˜ê¸‰ê¸ˆ ìƒì„¸ ì •ë³´ ì¶”ì¶œ

{'='*50}

"""
            
            return metadata + analysis
            
        except Exception as e:
            logger.error(f"í•´ì•½í™˜ê¸‰ê¸ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"âŒ í•´ì•½í™˜ê¸‰ê¸ˆ ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _extract_surrender_related_text(self, text: str, keywords: List[str]) -> str:
        """í•´ì•½í™˜ê¸‰ê¸ˆ ê´€ë ¨ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
        lines = text.split('\n')
        surrender_lines = []
        
        for line in lines:
            if any(keyword in line for keyword in keywords):
                surrender_lines.append(line)
                # ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ë„ í¬í•¨ (í‘œ êµ¬ì¡° ë³´ì¡´)
                if '|' in line or any(char.isdigit() for char in line):
                    surrender_lines.append(line)
        
        return '\n'.join(surrender_lines)
    
    def _extract_table_data_from_pages(self, pages: List[Dict[str, Any]]) -> str:
        """í˜ì´ì§€ì—ì„œ í‘œ ë°ì´í„° ì¶”ì¶œ (ê°œì„ ëœ í•´ì•½í™˜ê¸‰ê¸ˆ í‘œ íŒŒì‹±)"""
        try:
            from parsing.table_parser import TableParser
            
            table_data = []
            parser = TableParser()
            
            for page in pages:
                page_text = page.get('text', '')
                if page_text:
                    # í•´ì•½í™˜ê¸‰ê¸ˆ í‘œ íŒŒì‹±
                    surrender_table = parser.parse_surrender_value_table(page_text)
                    if surrender_table:
                        table_data.extend(surrender_table)
            
            if not table_data:
                return "í‘œ ë°ì´í„° ì—†ìŒ"
            
            # í‘œ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
            formatted_data = []
            for item in table_data:
                if item.get('type') == 'data':
                    columns = item.get('columns', [])
                    amounts = item.get('amounts', [])
                    
                    if len(columns) >= 6:  # ê²½ê³¼ê¸°ê°„, ë‚©ì…ë³´í—˜ë£Œ, ì ë¦½ë¶€ë¶„í™˜ê¸‰ê¸ˆ, ë³´ì¥ë¶€ë¶„í™˜ê¸‰ê¸ˆ, í™˜ê¸‰ê¸ˆ(í•©ê³„), í™˜ê¸‰ë¥ 
                        formatted_data.append({
                            "period": columns[0] if len(columns) > 0 else "",
                            "premium": columns[1] if len(columns) > 1 else "",
                            "surrender_amount": columns[4] if len(columns) > 4 else "",
                            "surrender_rate": columns[5] if len(columns) > 5 else "",
                            "amounts": amounts
                        })
            
            return str(formatted_data)
            
        except Exception as e:
            logger.error(f"í‘œ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "í‘œ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨"

    def analyze_for_detail(self, pages: List[Dict[str, Any]], file_name: str) -> str:
        """
        ìƒí’ˆ ìƒì„¸ ì •ë³´ ì œê³µìš© ì‹¬ì¸µ ë¶„ì„
        
        Args:
            pages: PDF í˜ì´ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            file_name: PDF íŒŒì¼ëª…
            
        Returns:
            ìƒì„¸ ì •ë³´ ì œê³µì— íŠ¹í™”ëœ ì¢…í•© ë¶„ì„
        """
        try:
            raw_text = self._combine_extracted_text(pages)
            
            if not raw_text.strip():
                return "âŒ ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # í† í° ì œí•œ ê³ ë ¤í•œ ìŠ¤ë§ˆíŠ¸ ì ˆë‹¨ (ìƒì„¸ ë¶„ì„ìš© - ì „ì²´ ë³´ì¡´)
            smart_text = self._smart_truncate_text(raw_text, max_input_tokens=80000)
            
            # ìƒì„¸ ë¶„ì„ìš© íŠ¹í™” í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¤ìŒì€ ë³´í—˜ ìƒí’ˆ ë¬¸ì„œ "{file_name}"ì—ì„œ ì¶”ì¶œí•œ ì „ì²´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ê³ ê°ì´ ì´ ìƒí’ˆì„ ìì„¸íˆ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

ì¶”ì¶œëœ í…ìŠ¤íŠ¸:
{smart_text}

ìƒì„¸ ë¶„ì„ ìš”êµ¬ì‚¬í•­:
1. **ì¢…í•© ìƒí’ˆ ê°œìš”**
   - ìƒí’ˆì˜ í•µì‹¬ ê°€ì¹˜ì™€ ëª©ì 
   - ëˆ„êµ¬ë¥¼ ìœ„í•œ ìƒí’ˆì¸ì§€
   - ì´ ìƒí’ˆì˜ ì² í•™ê³¼ ì„¤ê³„ ê°œë…

2. **ì™„ì „í•œ ë³´ì¥ êµ¬ì¡°**
   - ê¸°ë³¸ ë³´ì¥ ìƒì„¸ ì„¤ëª…
   - ëª¨ë“  íŠ¹ì•½ ë³´ì¥ ë‚´ìš© (ì¤‘ìš”ë„ ìˆœ)
   - ë³´ì¥ ì œì™¸ ì‚¬í•­ ë° ì£¼ì˜ì‚¬í•­
   - ê° ë³´ì¥ë³„ ì‹¤ì œ í™œìš© ì˜ˆì‹œ

3. **ë³´í—˜ë£Œ êµ¬ì¡° ë¶„ì„** ğŸš¨ ëª¨ë“  ê¸ˆì•¡ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ í‘œê¸°
   - ë³´í—˜ë£Œ ì‚°ì¶œ ê¸°ì¤€ (ì •í™•í•œ ê¸ˆì•¡ìœ¼ë¡œ ì˜ˆ: 92,540ì›)
   - ì—°ë ¹ë³„, ì„±ë³„ ì°¨ì´ (êµ¬ì²´ì  ê¸ˆì•¡)
   - ë³´í—˜ë£Œ í• ì¸/í• ì¦ ìš”ì¸
   - ê°±ì‹  ì¡°ê±´ ë° ë³´í—˜ë£Œ ë³€ë™
   
   ğŸ’¡ **ê¸ˆì•¡ í‘œê¸° ì›ì¹™**: ì›ë³¸ì—ì„œ 92,540ì›ì´ë©´ 92,540ì› ê·¸ëŒ€ë¡œ, ì ˆëŒ€ ë°˜ì˜¬ë¦¼ ê¸ˆì§€

4. **ê°€ì… ì¡°ê±´ ë° ì ˆì°¨**
   - ê°€ì… ê°€ëŠ¥ ì—°ë ¹ ë° ì¡°ê±´
   - ê±´ê°• ê³ ì§€ ì˜ë¬´ ì‚¬í•­
   - í•„ìš” ì„œë¥˜ ë° ì ˆì°¨
   - ê°€ì… í›„ ì£¼ì˜ì‚¬í•­

5. **ì‹¤ì „ í™œìš© ê°€ì´ë“œ**
   - ë³´í—˜ê¸ˆ ì²­êµ¬ ì ˆì°¨
   - ìì£¼ ë°œìƒí•˜ëŠ” ì‚¬ê³ ë³„ ë³´ìƒ ë²”ìœ„
   - ë³´í—˜ê¸ˆ ì§€ê¸‰ ì œì™¸ ì‚¬ë¡€
   - ê³ ê°ì´ ì•Œì•„ë‘ë©´ ì¢‹ì€ íŒ

6. **ì¥ë‹¨ì  ì‹¬ì¸µ ë¶„ì„**
   - ì´ ìƒí’ˆì˜ ëª…í™•í•œ ì¥ì 
   - í•œê³„ë‚˜ ì•„ì‰¬ìš´ ì 
   - ë‹¤ë¥¸ ìƒí’ˆê³¼ì˜ ì°¨ë³„ì 
   - ê°œì„  ì œì•ˆ

7. **ìƒì• ì£¼ê¸°ë³„ í™œìš©ë²•**
   - ì—°ë ¹ëŒ€ë³„ í™œìš© ì „ëµ
   - ê°€ì¡± ìƒí™©ë³„ ìµœì  ì„¤ê³„
   - ë‹¤ë¥¸ ë³´í—˜ê³¼ì˜ ì¡°í•© ë°©ë²•

8. **ìˆ˜ì¹˜ ì •ë³´ ì™„ì „ ì •ë¦¬**
   - ëª¨ë“  ë³´í—˜ë£Œ ì •ë³´ í…Œì´ë¸”
   - í•´ì•½í™˜ê¸‰ê¸ˆ ìƒì„¸ í‘œ
   - ê°±ì‹  ë³´í—˜ë£Œ ë³€ë™ ì˜ˆì‹œ
   - ë³´ì¥ ê¸ˆì•¡ë³„ ë¹„êµí‘œ

ê²°ê³¼ í˜•ì‹:
# ğŸ“– [{file_name}] ì™„ì „ ë¶„ì„ ê°€ì´ë“œ

## ğŸ¯ ìƒí’ˆ ì² í•™ ë° í•µì‹¬ ê°€ì¹˜
[ì´ ìƒí’ˆì´ ì¶”êµ¬í•˜ëŠ” ê°€ì¹˜ì™€ ì„¤ê³„ ì² í•™]

## ğŸ—ï¸ ì™„ì „í•œ ë³´ì¥ êµ¬ì¡°
### ğŸ›¡ï¸ ê¸°ë³¸ ë³´ì¥ (ì£¼ê³„ì•½)
[ìƒì„¸í•œ ê¸°ë³¸ ë³´ì¥ ì„¤ëª…]

### â­ íŠ¹ì•½ ë³´ì¥ ì™„ì „ ê°€ì´ë“œ
[ëª¨ë“  íŠ¹ì•½ì„ ì¤‘ìš”ë„ìˆœìœ¼ë¡œ ìƒì„¸ ì„¤ëª…]

### âš ï¸ ë³´ì¥ ì œì™¸ ë° ì£¼ì˜ì‚¬í•­
[ê³ ê°ì´ ë°˜ë“œì‹œ ì•Œì•„ì•¼ í•  ì œì™¸ ì‚¬í•­]

## ğŸ’° ë³´í—˜ë£Œ êµ¬ì¡° ì™„ì „ ë¶„ì„
### ğŸ“Š ë³´í—˜ë£Œ ì‚°ì¶œ ê¸°ì¤€
[ë³´í—˜ë£Œ ê²°ì • ìš”ì†Œë“¤]

### ğŸ“ˆ ê°±ì‹  ë° ë³€ë™ ì¡°ê±´
[ë³´í—˜ë£Œ ë³€ë™ ê°€ëŠ¥ì„±]

## ğŸ“‹ ê°€ì… ê°€ì´ë“œ
### âœ… ê°€ì… ì¡°ê±´
[ìƒì„¸í•œ ê°€ì… ìê²© ë° ì¡°ê±´]

### ğŸ“ í•„ìš” ì ˆì°¨
[ë‹¨ê³„ë³„ ê°€ì… ê³¼ì •]

## ğŸ”§ ì‹¤ì „ í™œìš© ë§¤ë‰´ì–¼
### ğŸ’Š ë³´í—˜ê¸ˆ ì²­êµ¬ ê°€ì´ë“œ
[ì‹¤ì œ ì²­êµ¬ ì‹œ í•„ìš”í•œ ëª¨ë“  ì •ë³´]

### ğŸ“š ì‚¬ë¡€ë³„ ë³´ìƒ ë²”ìœ„
[êµ¬ì²´ì ì¸ ìƒí™©ë³„ ë³´ìƒ ì˜ˆì‹œ]

## âš–ï¸ ì¥ë‹¨ì  ì™„ì „ ë¶„ì„
### âœ… ëª…í™•í•œ ì¥ì 
[ì´ ìƒí’ˆì˜ í™•ì‹¤í•œ ê°•ì ë“¤]

### âš ï¸ í•œê³„ ë° ê°œì„ ì 
[ì†”ì§í•œ ì•„ì‰¬ìš´ ì ë“¤]

## ğŸ¯ ìƒì• ì£¼ê¸°ë³„ í™œìš© ì „ëµ
### ğŸ‘¶ ì—°ë ¹ëŒ€ë³„ ì „ëµ
[ê° ì—°ë ¹ì—ì„œì˜ ìµœì  í™œìš©ë²•]

### ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ê°€ì¡± ìƒí™©ë³„ ì„¤ê³„
[ê°€ì¡± êµ¬ì„±ì— ë”°ë¥¸ ë§ì¶¤ ì „ëµ]

## ğŸ“Š ì™„ì „í•œ ìˆ˜ì¹˜ ì •ë³´
### ğŸ’° ë³´í—˜ë£Œ ìƒì„¸í‘œ
[ëª¨ë“  ë³´í—˜ë£Œ ì •ë³´ë¥¼ í‘œë¡œ ì •ë¦¬]

### ğŸ“ˆ í•´ì•½í™˜ê¸‰ê¸ˆ í‘œ
[ê²½ê³¼ ê¸°ê°„ë³„ ìƒì„¸ í™˜ê¸‰ ì •ë³´]

### ğŸ”„ ê°±ì‹  ë³´í—˜ë£Œ ì˜ˆì‹œ
[ê°±ì‹  ì‹œ ë³´í—˜ë£Œ ë³€ë™ ì˜ˆì¸¡]

## ğŸ’¡ ì „ë¬¸ê°€ ì¡°ì–¸
[ì´ ìƒí’ˆì„ ê³ ë ¤í•  ë•Œ ë°˜ë“œì‹œ ì•Œì•„ë‘˜ ì ë“¤]
"""

            messages = [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ë³´í—˜ìƒí’ˆ ìƒì„¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì´ ìƒí’ˆì„ ì™„ì „íˆ ì´í•´í•˜ê³  í˜„ëª…í•œ ì„ íƒì„ í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”. ëª¨ë“  ë‚´ìš©ì„ í¬í•¨í•˜ë˜ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ğŸš¨ ì¤‘ìš”: ëª¨ë“  ê¸ˆì•¡ê³¼ ìˆ«ìëŠ” ì›ë³¸ ë¬¸ì„œì˜ ì •í™•í•œ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ì ˆëŒ€ ë°˜ì˜¬ë¦¼í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ]
            
            response = self._safe_api_call(
                messages=messages,
                max_tokens=8000,  # ìƒì„¸ ë¶„ì„ì´ë¯€ë¡œ ë” ë§ì€ í† í° í• ë‹¹
                retries=3,
                delay=2
            )
            
            if response is None:
                # GPT ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ë¦¬ ì‹œë„
                logger.warning("GPT API ì‹¤íŒ¨, ê¸°ë³¸ í…ìŠ¤íŠ¸ í¬ë§·íŒ… ì‚¬ìš©")
                return self._fallback_formatting(pages, file_name)
            
            analysis = response.choices[0].message.content.strip()
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            from datetime import datetime
            metadata = f"""ğŸ“– ìƒí’ˆ ìƒì„¸ ë¶„ì„ ê²°ê³¼
{'='*50}

ğŸ“ íŒŒì¼ëª…: {file_name}
ğŸ“‘ í˜ì´ì§€ ìˆ˜: {len(pages)}
â° ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ¯ ë¶„ì„ ëª©ì : ìƒí’ˆ ìƒì„¸ ì •ë³´ ì œê³µ

{'='*50}

"""
            
            return metadata + analysis
            
        except Exception as e:
            logger.error(f"ìƒí’ˆ ìƒì„¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return f"âŒ ìƒì„¸ ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
